{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MACHINE LEARING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Burada yaptığım çalışmalar \"e-mailde belirttiğim gibi\" makine öğrenmesi ile ilgili öğrendiklerimin hem teorik hemde kodlama örnekleridir. Yine mailde belirttiğim gibi tez için yazmaya çalışılan program ve ona ait rapor gelecek haftadan itibaren incelenmesi için gönderilecektir.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Önemli Not: kodların yanındaki sayıların hiçbir önemi yoktur. Bu sayılar kodlama esnasında yapılan hatalardan, geriye dönerek farklı bir kütüphane eklenmesinden dolayı ardışık değildir.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Önemli NOT: Algoritmanın anlatıldığı kısımdaki örnekler benim makine öğrenmesini çalıştığım veri setiyle aynı değiltir. Bu sebeple kafaksrışıklığı oabilir. 1. veri seti televizyon, radyo ve gazete satışlarıyla ilgiliyken, 2. veri seti bezbol oyuncularının ücretleriyle ilgilidir. 3. veri seti ise diyabet hastalarının bilgilerinüi taşımaktadır.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1- LINEAR REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SIMPLE LINEAR REGRESSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression is a machine learning algorithm based on supervised learning. It performs a regression task. Regression models a target prediction value based on independent variables. It is mostly used for finding out the relationship between variables and forecasting. Different regression models differ based on – the kind of relationship between dependent and independent variables, they are considering and the number of independent variables being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression performs the task to predict a dependent variable value (y) based on a given independent variable (x). So, this regression technique finds out a linear relationship between x (input) and y(output). Hence, the name is Linear Regression.\n",
    "In the figure above, X (input) is the work experience and Y (output) is the salary of a person. The regression line is the best fit line for our model.\n",
    "\n",
    "**Hypothesis function for Linear Regression :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training the model we are given :\n",
    "**x:** input training data (univariate – one input variable(parameter)),\n",
    "**y:** labels to data (supervised learning)\n",
    "\n",
    "When training the model – it fits the best line to predict the value of y for a given value of x. The model gets the best regression fit line by finding the best θ1 and θ2 values.\n",
    "**θ1:** intercept,\n",
    "**θ2:** coefficient of x\n",
    "\n",
    "Once we find the best θ1 and θ2 values, we get the best fit line. So when we are finally using our model for prediction, it will predict the value of y for the input value of x.\n",
    "\n",
    "**How to update θ1 and θ2 values to get the best fit line ?**\n",
    "\n",
    "**Cost Function (J):**\n",
    "By achieving the best-fit regression line, the model aims to predict y value such that the error difference between predicted value and true value is minimum. So, it is very important to update the θ1 and θ2 values, to reach the best value that minimize the error between predicted y value (pred) and true y value (y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CODING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bu çalışmada televizyon, radyo ve gazete satışlarının lineer regressyonu çıkarılmıştır. Burada sales bağımlı değişken; televizyon, radyo ve gazete ise bağımsız değişkenlerdir.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\PYTON\\\\Desktop\\\\machine_learning\\\\Handan_Olgar\\\\original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,1:len(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  radio  newspaper  sales\n",
       "0    230.1   37.8       69.2   22.1\n",
       "1     44.5   39.3       45.1   10.4\n",
       "2     17.2   45.9       69.3    9.3\n",
       "3    151.5   41.3       58.5   18.5\n",
       "4    180.8   10.8       58.4   12.9\n",
       "..     ...    ...        ...    ...\n",
       "195   38.2    3.7       13.8    7.6\n",
       "196   94.2    4.9        8.1    9.7\n",
       "197  177.0    9.3        6.4   12.8\n",
       "198  283.6   42.0       66.2   25.5\n",
       "199  232.1    8.6        8.7   13.4\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   TV         200 non-null    float64\n",
      " 1   radio      200 non-null    float64\n",
      " 2   newspaper  200 non-null    float64\n",
      " 3   sales      200 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 6.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.jointplot(x = \"TV\", y = \"sales\", data = df, kind = \"reg\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.jointplot(x = \"radio\", y = \"sales\", data = df, kind = \"reg\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.jointplot(x=\"newspaper\", y=\"sales\", data=df, kind=\"reg\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[[\"TV\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV\n",
       "0  230.1\n",
       "1   44.5\n",
       "2   17.2\n",
       "3  151.5\n",
       "4  180.8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"sales\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales\n",
       "0   22.1\n",
       "1   10.4\n",
       "2    9.3\n",
       "3   18.5\n",
       "4   12.9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL NESNESİ OLUŞTURULACAK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODELİN KURULMASI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = reg.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_decision_function',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_preprocess_data',\n",
       " '_residues',\n",
       " '_set_intercept',\n",
       " 'coef_',\n",
       " 'copy_X',\n",
       " 'fit',\n",
       " 'fit_intercept',\n",
       " 'get_params',\n",
       " 'intercept_',\n",
       " 'n_jobs',\n",
       " 'normalize',\n",
       " 'predict',\n",
       " 'rank_',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'singular_']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.03259355])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04753664]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**yi = 0.04753664xi + 7.03259355**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_R kare ifadesi şu şekildedir:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.611875050850071"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = df[[\"radio\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   radio\n",
       "0   37.8\n",
       "1   39.3\n",
       "2   45.9\n",
       "3   41.3\n",
       "4   10.8"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = reg1.fit(z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20249578]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.3116381])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**y = 0.20249578z + 9.3116381**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33203245544529525"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.score(z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = df[[\"newspaper\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = reg2.fit(q,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0546931]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.35140707])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05212044544430516"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.score(q,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_TAHMİN_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.regplot(df[\"TV\"], df[\"sales\"], ci =None, scatter_kws={\"color\":\"r\",\"s\":9})\n",
    "g.set_title(\"Model Denklemi:  y = 0.04753664*x + 7.03259355\")\n",
    "g.set_xlabel(\"TV Harcamaları\")\n",
    "g.set_ylabel(\"Satış Sayısı\")\n",
    "plt.xlim(-10,310)\n",
    "plt.ylim(bottom=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[244.71579571]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[5000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeni_deger = [[5], [15], [30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.27027675],\n",
       "       [7.74564316],\n",
       "       [8.45869276]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(yeni_deger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ARTIKLAR (HATALAR)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MSE: HATA KARELER ORTALAMASI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSE: HATA KARELER ORTALAMASININ KAREKÖKÜ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales\n",
       "0   22.1\n",
       "1   10.4\n",
       "2    9.3\n",
       "3   18.5\n",
       "4   12.9"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   radio\n",
       "0   37.8\n",
       "1   39.3\n",
       "2   45.9\n",
       "3   41.3\n",
       "4   10.8"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tahmin_edilen_y = pd.DataFrame(model.predict(x)[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "gercek_y = y[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.970775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.147974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.850224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.234395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.627218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>8.848493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>11.510545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>15.446579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>20.513985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>18.065848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    17.970775\n",
       "1     9.147974\n",
       "2     7.850224\n",
       "3    14.234395\n",
       "4    15.627218\n",
       "..         ...\n",
       "195   8.848493\n",
       "196  11.510545\n",
       "197  15.446579\n",
       "198  20.513985\n",
       "199  18.065848\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tahmin_edilen_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sales\n",
       "0     22.1\n",
       "1     10.4\n",
       "2      9.3\n",
       "3     18.5\n",
       "4     12.9\n",
       "..     ...\n",
       "195    7.6\n",
       "196    9.7\n",
       "197   12.8\n",
       "198   25.5\n",
       "199   13.4\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gercek_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "hatalar = pd.concat([gercek_y, tahmin_edilen_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "      <td>17.970775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "      <td>9.147974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "      <td>7.850224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>14.234395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "      <td>15.627218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>7.6</td>\n",
       "      <td>8.848493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>9.7</td>\n",
       "      <td>11.510545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>12.8</td>\n",
       "      <td>15.446579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>25.5</td>\n",
       "      <td>20.513985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>13.4</td>\n",
       "      <td>18.065848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sales          0\n",
       "0     22.1  17.970775\n",
       "1     10.4   9.147974\n",
       "2      9.3   7.850224\n",
       "3     18.5  14.234395\n",
       "4     12.9  15.627218\n",
       "..     ...        ...\n",
       "195    7.6   8.848493\n",
       "196    9.7  11.510545\n",
       "197   12.8  15.446579\n",
       "198   25.5  20.513985\n",
       "199   13.4  18.065848\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "hatalar.columns = [\"gercek_y\", \"tahmin_edilen_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gercek_y</th>\n",
       "      <th>tahmin_edilen_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "      <td>17.970775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "      <td>9.147974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "      <td>7.850224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>14.234395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "      <td>15.627218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>7.6</td>\n",
       "      <td>8.848493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>9.7</td>\n",
       "      <td>11.510545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>12.8</td>\n",
       "      <td>15.446579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>25.5</td>\n",
       "      <td>20.513985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>13.4</td>\n",
       "      <td>18.065848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gercek_y  tahmin_edilen_y\n",
       "0        22.1        17.970775\n",
       "1        10.4         9.147974\n",
       "2         9.3         7.850224\n",
       "3        18.5        14.234395\n",
       "4        12.9        15.627218\n",
       "..        ...              ...\n",
       "195       7.6         8.848493\n",
       "196       9.7        11.510545\n",
       "197      12.8        15.446579\n",
       "198      25.5        20.513985\n",
       "199      13.4        18.065848\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "hatalar[\"hata\"] = hatalar[\"gercek_y\"] - hatalar[\"tahmin_edilen_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gercek_y</th>\n",
       "      <th>tahmin_edilen_y</th>\n",
       "      <th>hata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "      <td>17.970775</td>\n",
       "      <td>4.129225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "      <td>9.147974</td>\n",
       "      <td>1.252026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "      <td>7.850224</td>\n",
       "      <td>1.449776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>14.234395</td>\n",
       "      <td>4.265605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "      <td>15.627218</td>\n",
       "      <td>-2.727218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>7.6</td>\n",
       "      <td>8.848493</td>\n",
       "      <td>-1.248493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>9.7</td>\n",
       "      <td>11.510545</td>\n",
       "      <td>-1.810545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>12.8</td>\n",
       "      <td>15.446579</td>\n",
       "      <td>-2.646579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>25.5</td>\n",
       "      <td>20.513985</td>\n",
       "      <td>4.986015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>13.4</td>\n",
       "      <td>18.065848</td>\n",
       "      <td>-4.665848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gercek_y  tahmin_edilen_y      hata\n",
       "0        22.1        17.970775  4.129225\n",
       "1        10.4         9.147974  1.252026\n",
       "2         9.3         7.850224  1.449776\n",
       "3        18.5        14.234395  4.265605\n",
       "4        12.9        15.627218 -2.727218\n",
       "..        ...              ...       ...\n",
       "195       7.6         8.848493 -1.248493\n",
       "196       9.7        11.510545 -1.810545\n",
       "197      12.8        15.446579 -2.646579\n",
       "198      25.5        20.513985  4.986015\n",
       "199      13.4        18.065848 -4.665848\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "hatalar[\"MSE\"] = hatalar[\"hata\"]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gercek_y</th>\n",
       "      <th>tahmin_edilen_y</th>\n",
       "      <th>hata</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "      <td>17.970775</td>\n",
       "      <td>4.129225</td>\n",
       "      <td>17.050503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "      <td>9.147974</td>\n",
       "      <td>1.252026</td>\n",
       "      <td>1.567569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "      <td>7.850224</td>\n",
       "      <td>1.449776</td>\n",
       "      <td>2.101851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>14.234395</td>\n",
       "      <td>4.265605</td>\n",
       "      <td>18.195390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "      <td>15.627218</td>\n",
       "      <td>-2.727218</td>\n",
       "      <td>7.437719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>7.6</td>\n",
       "      <td>8.848493</td>\n",
       "      <td>-1.248493</td>\n",
       "      <td>1.558735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>9.7</td>\n",
       "      <td>11.510545</td>\n",
       "      <td>-1.810545</td>\n",
       "      <td>3.278073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>12.8</td>\n",
       "      <td>15.446579</td>\n",
       "      <td>-2.646579</td>\n",
       "      <td>7.004380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>25.5</td>\n",
       "      <td>20.513985</td>\n",
       "      <td>4.986015</td>\n",
       "      <td>24.860348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>13.4</td>\n",
       "      <td>18.065848</td>\n",
       "      <td>-4.665848</td>\n",
       "      <td>21.770136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gercek_y  tahmin_edilen_y      hata        MSE\n",
       "0        22.1        17.970775  4.129225  17.050503\n",
       "1        10.4         9.147974  1.252026   1.567569\n",
       "2         9.3         7.850224  1.449776   2.101851\n",
       "3        18.5        14.234395  4.265605  18.195390\n",
       "4        12.9        15.627218 -2.727218   7.437719\n",
       "..        ...              ...       ...        ...\n",
       "195       7.6         8.848493 -1.248493   1.558735\n",
       "196       9.7        11.510545 -1.810545   3.278073\n",
       "197      12.8        15.446579 -2.646579   7.004380\n",
       "198      25.5        20.513985  4.986015  24.860348\n",
       "199      13.4        18.065848 -4.665848  21.770136\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.512652915656753"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(hatalar[\"MSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MULTIPLE LINEAR REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple linear regression ( Çoklu Doğrusal Regresyon) en yaygın kullanılan linear regression analizidir.\n",
    "Linear Regression 1 tane bağımlı ve 1 tane de bağımsız değişkenle çalışıyordu. ( y = ax +b , y : bağımsız, x : bağımlı ) Multiple linear regression birden fazla bağımsız değişkenle çalışabilir.\n",
    "**y= b0 + a x1 + bx2 + c a x3 + d**\n",
    "Örneğin Linear Regression’da aylara göre satış tahmini ( bağımsız değişken) yapmıldıysa, Multiple linear regression‘da da kilo, yaş ve boy verisinden ayakkabı numarasını tahmin ettirebiliriz. Burada kilo, yaş, boy bağımsız değişkendir yani birden fazladır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummy Variable ( Kukla Değişken )**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy variable bir değişkeni ifade eden başka bir değişken olarak tanımlanabilir. Örneğin yukarıdaki cinsiyet kolonu OneHotEncoder ile kategorik veriden sayısal veriye dönüştürülmüştür. Dönüşüm işlemi yapıldıktan sonra elimizdeki kolon sayısı 4'ten 6'ya çıkmıştır. OneHotEncoder sonucu e ve k kolonlarıda dahil olmuştur. Bu veri setini doğrudan makine öğrenme algoritmasına vericek olursak sonucumuzun hatalı çıkma ihtimali yüksektir çünkü bu 6 kolondan 3'ü ( cinsiyet, e, k) özünde aynıdır yani birinin değişmesi diğer kolon değerlerinide etkilemektedir. ( bağımlı ) Bu duruma Dummy variable trap ( Kukla değişken tuzağı ) denir.\n",
    "Bu durumdan kurtulmak için 3 kolondan ( cinsiyet, e, k) ikisini çıkarmalıyız ve makine öğrenme algoritmasına veri setini öyle vermeliyiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not : Bazı makine öğrenme algoritmaları dummy variable trap olayına karşı bağışıklıdır.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P Value ( Olasılık Değeri )**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P değeri bir karşılaştırmada istatiksel anlamlılık düzeyine işaret eder. Olası hata miktarını gösterir. Ünlü bir istatistikçi olan Fisher tarafından bu hatanın maksimum kabul edilebilir düzeyi 0,05 olarak önerilmiş ve kabul görmüştür.\n",
    "Bir test sonucunda bulunan P değeri 0,05'in altında ise karşılaştırma sonucunda anlamlı farklılık vardır.\n",
    "Bir örnek oluşturulursa; yaş, ülke, cinsiyet ve kilo verilerini alıp kişinin boyunu tahmin etmeye çalışacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backward Elimination ( Geri Eleme )**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her bir değişkenin sistem üzerine bir etkisi vardır. Bazı değişkenlerin sisteme etkisi yüksekken bazılarının azdır. Sisteme etkisi az olan bağımsız değişkenlerin ortadan kaldırılması daha iyi bir model kurmamıza olanak sağlar. Backward Elimination yöntemini kullanarak daha iyi modeller oluşturabiliriz.\n",
    "    (1) P değerini seçin ( Genellikle bu değer 0.05 olur)\n",
    "    (2) Tüm bağımsız değişkenleri dahil ettiğiniz bir model kurun\n",
    "    (3) Her bir bağımsız değişkenin p değeri incelenir. Eğer Pdeğeri model için belirlenenden daha büyük ise bu bağımsız değişken modelden çıkarılır. Tekrar çalıştırılır.\n",
    "    (4) Bütün p değerleri belirlediğimiz değerden küçük ise modelimiz hazırdır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kırmızı daire içine alınan alan P değerlerimizdir. x5 ( kilo) kolonu bizim belirlediğimiz P değerinden ( 0.05 ) yüksektir. Bir sonraki adımda bu kolon çıkartılır ve program tekrar çalıştırılır. Kırmızı dairedeki tüm değerler P değerinden küçük oluncaya kadar bu işlem devam eder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CODING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\PYTON\\\\Desktop\\\\machine_learning\\\\Handan_Olgar\\\\original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,1:len(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BAĞIMSIZ DEĞİŞKENLER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(\"sales\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BAĞIMLI DEĞİŞKENLER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"sales\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales\n",
       "0   22.1\n",
       "1   10.4\n",
       "2    9.3\n",
       "3   18.5\n",
       "4   12.9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper\n",
       "0  230.1   37.8       69.2\n",
       "1   44.5   39.3       45.1\n",
       "2   17.2   45.9       69.3\n",
       "3  151.5   41.3       58.5\n",
       "4  180.8   10.8       58.4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STATSMODEL İLE MODEL KURMAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sm.OLS(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>sales</td>      <th>  R-squared (uncentered):</th>      <td>   0.982</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.982</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   3566.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 03 Apr 2020</td> <th>  Prob (F-statistic):</th>          <td>2.43e-171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:13:49</td>     <th>  Log-Likelihood:    </th>          <td> -423.54</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th>          <td>   853.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   197</td>      <th>  BIC:               </th>          <td>   863.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>        <td>    0.0538</td> <td>    0.001</td> <td>   40.507</td> <td> 0.000</td> <td>    0.051</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>radio</th>     <td>    0.2222</td> <td>    0.009</td> <td>   23.595</td> <td> 0.000</td> <td>    0.204</td> <td>    0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>newspaper</th> <td>    0.0168</td> <td>    0.007</td> <td>    2.517</td> <td> 0.013</td> <td>    0.004</td> <td>    0.030</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.982</td> <th>  Durbin-Watson:     </th> <td>   2.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.050</td> <th>  Jarque-Bera (JB):  </th> <td>   7.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.232</td> <th>  Prob(JB):          </th> <td>  0.0296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.794</td> <th>  Cond. No.          </th> <td>    12.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                  sales   R-squared (uncentered):                   0.982\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.982\n",
       "Method:                 Least Squares   F-statistic:                              3566.\n",
       "Date:                Fri, 03 Apr 2020   Prob (F-statistic):                   2.43e-171\n",
       "Time:                        00:13:49   Log-Likelihood:                         -423.54\n",
       "No. Observations:                 200   AIC:                                      853.1\n",
       "Df Residuals:                     197   BIC:                                      863.0\n",
       "Df Model:                           3                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "TV             0.0538      0.001     40.507      0.000       0.051       0.056\n",
       "radio          0.2222      0.009     23.595      0.000       0.204       0.241\n",
       "newspaper      0.0168      0.007      2.517      0.013       0.004       0.030\n",
       "==============================================================================\n",
       "Omnibus:                        5.982   Durbin-Watson:                   2.038\n",
       "Prob(Omnibus):                  0.050   Jarque-Bera (JB):                7.039\n",
       "Skew:                          -0.232   Prob(JB):                       0.0296\n",
       "Kurtosis:                       3.794   Cond. No.                         12.6\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### scikit learn ile model kurmak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04576465,  0.18853002, -0.00103749]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.93888937])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_TAHMİN_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_veri = [[30],[10],[40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_veri = pd.DataFrame(model_veri).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2\n",
       "0  30  10  40"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_veri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.15562918]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(model_veri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales\n",
       "0   22.1\n",
       "1   10.4\n",
       "2    9.3\n",
       "3   18.5\n",
       "4   12.9"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20.52397441],\n",
       "       [12.33785482],\n",
       "       [12.30767078],\n",
       "       [17.59782951],\n",
       "       [13.18867186],\n",
       "       [12.47834763],\n",
       "       [11.72975995],\n",
       "       [12.12295317],\n",
       "       [ 3.72734086],\n",
       "       [12.55084872]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.784126314510936"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = mean_squared_error(y, model.predict(x))\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6685701407225697"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "RMSE = np.sqrt(MSE)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MODEL TUNING (MODEL DOĞRULAMA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper\n",
       "0  230.1   37.8       69.2\n",
       "1   44.5   39.3       45.1\n",
       "2   17.2   45.9       69.3\n",
       "3  151.5   41.3       58.5\n",
       "4  180.8   10.8       58.4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales\n",
       "0   22.1\n",
       "1   10.4\n",
       "2    9.3\n",
       "3   18.5\n",
       "4   12.9"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sinama seti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>13.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>90.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>23.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>18.7</td>\n",
       "      <td>12.1</td>\n",
       "      <td>23.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>204.1</td>\n",
       "      <td>32.9</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>7.3</td>\n",
       "      <td>28.1</td>\n",
       "      <td>41.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  radio  newspaper\n",
       "108   13.1    0.4       25.6\n",
       "107   90.4    0.3       23.2\n",
       "189   18.7   12.1       23.4\n",
       "14   204.1   32.9       46.0\n",
       "56     7.3   28.1       41.4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>210.8</td>\n",
       "      <td>49.6</td>\n",
       "      <td>37.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>202.5</td>\n",
       "      <td>22.3</td>\n",
       "      <td>31.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>95.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>280.2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>253.8</td>\n",
       "      <td>21.3</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  radio  newspaper\n",
       "58   210.8   49.6       37.7\n",
       "40   202.5   22.3       31.6\n",
       "34    95.7    1.4        7.4\n",
       "102  280.2   10.1       21.4\n",
       "184  253.8   21.3       30.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sales\n",
       "108    5.3\n",
       "107    8.7\n",
       "189    6.7\n",
       "14    19.0\n",
       "56     5.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sales\n",
       "58    23.8\n",
       "40    16.6\n",
       "34     9.5\n",
       "102   14.8\n",
       "184   17.6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7369025901470923"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### EĞİTİM HATASI\n",
    "np.sqrt(mean_squared_error(y_train, model.predict(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4113417558581591"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEST HATASI\n",
    "np.sqrt(mean_squared_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-katlı cross validation\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.62375953, -3.81875608, -3.43828142, -2.27748673, -7.25325414,\n",
       "       -1.88303708, -2.80517715, -3.68594486, -1.12810834, -3.96330989])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, x_train, y_train, cv=10, scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1877115209443563"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV MSE\n",
    "np.mean(-cross_val_score(model, x_train, y_train, cv=10, scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7854163438661461"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CV RMSE\n",
    "np.sqrt(np.mean(-cross_val_score(model, x_train, y_train, cv=10, scoring=\"neg_mean_squared_error\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LASSO REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression is a type of linear regression that uses shrinkage. Shrinkage is where data values are shrunk towards a central point, like the mean. The lasso procedure encourages simple, sparse models (i.e. models with fewer parameters). This particular type of regression is well-suited for models showing high levels of muticollinearity or when you want to automate certain parts of model selection, like variable selection/parameter elimination.\n",
    "\n",
    "The acronym “LASSO” stands for **L**east **A**bsolute **S**hrinkage and **S**election **O**perator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **L1 Regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression performs L1 regularization, which adds a penalty equal to the absolute value of the magnitude of coefficients. This type of regularization can result in sparse models with few coefficients; Some coefficients can become zero and eliminated from the model. Larger penalties result in coefficient values closer to zero, which is the ideal for producing simpler models. On the other hand, L2 regularization (e.g. Ridge regression) doesn’t result in elimination of coefficients or sparse models. This makes the Lasso far easier to interpret than the Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Performing the Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso solutions are quadratic programming problems, which are best solved with software (like Matlab). The goal of the algorithm is to minimize:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is the same as minimizing the sum of squares with constraint Σ |Bj≤ s. Some of the βs are shrunk to exactly zero, resulting in a regression model that’s easier to interpret.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tuning parameter, λ controls the strength of the L1 penalty. λ is basically the amount of shrinkage:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) When λ = 0, no parameters are eliminated. The estimate is equal to the one found with linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) As λ increases, more and more coefficients are set to zero and eliminated (theoretically, when λ = ∞, all coefficients are eliminated)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) As λ increases, bias increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) As λ decreases, variance increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an intercept is included in the model, it is usually left unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CODING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\PYTON\\\\Desktop\\\\machine_learning\\\\Handan_Olgar\\\\original1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dms =pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis=1).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([x_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>497</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2703</td>\n",
       "      <td>806</td>\n",
       "      <td>32</td>\n",
       "      <td>379</td>\n",
       "      <td>311</td>\n",
       "      <td>138</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>325</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>492</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>5511</td>\n",
       "      <td>1511</td>\n",
       "      <td>39</td>\n",
       "      <td>897</td>\n",
       "      <td>451</td>\n",
       "      <td>875</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>313</td>\n",
       "      <td>381</td>\n",
       "      <td>20</td>\n",
       "      <td>875.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>475</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1700</td>\n",
       "      <td>433</td>\n",
       "      <td>7</td>\n",
       "      <td>217</td>\n",
       "      <td>93</td>\n",
       "      <td>146</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>385.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>573</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>3198</td>\n",
       "      <td>857</td>\n",
       "      <td>97</td>\n",
       "      <td>470</td>\n",
       "      <td>420</td>\n",
       "      <td>332</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>1314</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>960.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>631</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>4908</td>\n",
       "      <td>1457</td>\n",
       "      <td>30</td>\n",
       "      <td>775</td>\n",
       "      <td>357</td>\n",
       "      <td>249</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  \\\n",
       "1      315    81      7    24   38     39     14    3449    835      69   \n",
       "2      479   130     18    66   72     76      3    1624    457      63   \n",
       "3      496   141     20    65   78     37     11    5628   1575     225   \n",
       "4      321    87     10    39   42     30      2     396    101      12   \n",
       "5      594   169      4    74   51     35     11    4408   1133      19   \n",
       "..     ...   ...    ...   ...  ...    ...    ...     ...    ...     ...   \n",
       "317    497   127      7    65   48     37      5    2703    806      32   \n",
       "318    492   136      5    76   50     94     12    5511   1511      39   \n",
       "319    475   126      3    61   43     52      6    1700    433       7   \n",
       "320    573   144      9    85   60     78      8    3198    857      97   \n",
       "321    631   170      9    77   44     31     11    4908   1457      30   \n",
       "\n",
       "     CRuns  CRBI  CWalks League Division  PutOuts  Assists  Errors  Salary  \\\n",
       "1      321   414     375      N        W      632       43      10   475.0   \n",
       "2      224   266     263      A        W      880       82      14   480.0   \n",
       "3      828   838     354      N        E      200       11       3   500.0   \n",
       "4       48    46      33      N        E      805       40       4    91.5   \n",
       "5      501   336     194      A        W      282      421      25   750.0   \n",
       "..     ...   ...     ...    ...      ...      ...      ...     ...     ...   \n",
       "317    379   311     138      N        E      325        9       3   700.0   \n",
       "318    897   451     875      A        E      313      381      20   875.0   \n",
       "319    217    93     146      A        W       37      113       7   385.0   \n",
       "320    470   420     332      A        E     1314      131      12   960.0   \n",
       "321    775   357     249      A        W      408        4       3  1000.0   \n",
       "\n",
       "    NewLeague  \n",
       "1           N  \n",
       "2           A  \n",
       "3           N  \n",
       "4           N  \n",
       "5           A  \n",
       "..        ...  \n",
       "317         N  \n",
       "318         A  \n",
       "319         A  \n",
       "320         A  \n",
       "321         A  \n",
       "\n",
       "[263 rows x 20 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 20)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8256653.399850384, tolerance: 3898.686956380658\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "lasso_model = Lasso().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.587450677337529"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.74875691e+00,  8.59204135e+00,  6.67993798e+00, -3.06715333e+00,\n",
       "       -1.91843070e+00,  5.32372890e+00,  8.39184117e+00, -1.63172447e-01,\n",
       "       -8.22311277e-02, -3.93602861e-01,  1.71118530e+00,  6.55730545e-01,\n",
       "       -6.48379405e-01,  2.59815358e-01,  2.73041157e-01, -4.41440454e-01,\n",
       "        8.54474011e+01, -9.59701213e+01, -2.13086605e+01])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### farklı lambda değerlerine karşılık gelen katsayılar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5469.558741439134, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6540.147679537535, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4001.75613726303, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5357.77493564412, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5543.611320462078, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38977.90211549215, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4436895.415746864, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6555245.313879337, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7517635.389992706, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7913116.552938657, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8063057.666015268, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8147851.972007666, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8195503.925140649, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8222772.970408573, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8238618.061152122, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8247931.056261426, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8254112.783082767, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8256643.474169196, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8256663.517485521, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8255732.406295837, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8254488.032216603, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8253238.172401866, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8252116.626715363, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8251167.59914859, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8250392.226499426, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8249772.80594322, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8249285.457096015, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8248906.058581409, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8248612.895175021, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8248387.613746921, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8248215.191106195, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8248083.6060414985, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8247983.409284997, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8247907.234834639, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8247849.397090836, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8247805.522216827, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8247772.261812311, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8247747.060921376, tolerance: 3898.686956380658\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "lasso =Lasso()\n",
    "coefs = []\n",
    "alphas = 10**np.linspace(10,-2,100)*.5\n",
    "for i in alphas:\n",
    "    lasso.set_params(alpha = i)\n",
    "    lasso.fit(x_train, y_train)\n",
    "    coefs.append(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TAHMİN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 377.26270596,  786.51524513,  495.14140718,  117.19492966,\n",
       "        429.04228506, 1002.11334796,  154.15381011,  359.68989378,\n",
       "        484.56926344,  915.91820524])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.predict(x_train)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 609.18826367,  696.96810702, 1009.06157391,  412.22773375,\n",
       "        409.25851712,  344.61472086,  662.19913564,  452.93891559,\n",
       "        913.97254298,  646.93182594])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.predict(x_test)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356.09758845540347"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41422798132366123"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MODEL TUNING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv_model = LassoCV(alphas= alphas, cv=10, max_iter=1000000).fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201.85086292982749"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_tuned = Lasso().set_params(alpha=lasso_cv_model.alpha_).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso_tuned.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363.6832708037447"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtBat         -1.052276\n",
       "Hits           5.342648\n",
       "HmRun          0.000000\n",
       "Runs           0.000000\n",
       "RBI            0.000000\n",
       "Walks          2.640006\n",
       "Years          0.000000\n",
       "CAtBat        -0.174125\n",
       "CHits          0.249805\n",
       "CHmRun        -0.000000\n",
       "CRuns          1.035075\n",
       "CRBI           0.469281\n",
       "CWalks        -0.186771\n",
       "PutOuts        0.272541\n",
       "Assists        0.170528\n",
       "Errors        -0.000000\n",
       "League_N       0.000000\n",
       "Division_W    -0.000000\n",
       "NewLeague_N    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fiyatlara etkisi olmayanlar o olarak atandı\n",
    "pd.Series(lasso_tuned.coef_, index=x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RIDGE REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression is a way to create a parsimonious model when the number of predictor variables in a set exceeds the number of observations, or when a data set has multicollinearity (correlations between predictor variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tikhivov’s method is basically the same as ridge regression, except that Tikhonov’s has a larger set. It can produce solutions even when your data set contains a lot of statistical noise (unexplained variation in a sample)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ridge Regression vs. Least Squares**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least squares regression isn’t defined at all when the number of predictors exceeds the number of observations; It doesn’t differentiate “important” from “less-important” predictors in a model, so it includes all of them. This leads to overfitting a model and failure to find unique solutions. Least squares also has issues dealing with multicollinearity in data. Ridge regression avoids all of these problems. It works in part because it doesn’t require unbiased estimators; While least squares produces unbiased estimates, variances can be so large that they may be wholly inaccurate. Ridge regression adds just enough bias to make the estimates reasonably reliable approximations to true population values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Shrinkage**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression uses a type of shrinkage estimator called a ridge estimator. Shrinkage estimators theoretically produce new estimators that are shrunk closer to the “true” population parameters. The ridge estimator is especially good at improving the least-squares estimate when multicollinearity is present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression belongs a class of regression tools that use L2 regularization. The other type of regularization, L1 regularization, limits the size of the coefficients by adding an L1 penalty equal to the absolute value of the magnitude of coefficients. This sometimes results in the elimination of some coefficients altogether, which can yield sparse models. L2 regularization adds an L2 penalty, which equals the square of the magnitude of coefficients. All coefficients are shrunk by the same factor (so none are eliminated). Unlike L1 regularization, L2 will not result in sparse models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tuning parameter (λ) controls the strength of the penalty term. When λ = 0, ridge regression equals least squares regression. If λ = ∞, all coefficients are shrunk to zero. The ideal penalty is therefore somewhere in between 0 and ∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **On Mathematics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLS regression uses the following formula to estimate coefficients:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If X is a centered and scaled matrix, the crossproduct matrix (X\"X) is nearly singular when the X-columns are highly correlated. Ridge regression adds a ridge parameter (k), of the identity matrix to the cross product matrix, forming a new matrix (X\"X + kI). It’s called ridge regression because the diagonal of ones in the correlation matrix can be described as a ridge. The new formula is used to find the coefficients:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing a value for k is not a simple task, which is perhaps one major reason why ridge regression isn’t used as much as least squares or logistic regression. You can read one way to find k in Dorugade and D. N. Kashid’s paper Alternative Method for Choosing Ridge Parameter for Regression.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CODING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\PYTON\\\\Desktop\\\\machine_learning\\\\Handan_Olgar\\\\original1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dms =pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis=1).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([x_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>497</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2703</td>\n",
       "      <td>806</td>\n",
       "      <td>32</td>\n",
       "      <td>379</td>\n",
       "      <td>311</td>\n",
       "      <td>138</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>325</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>492</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>5511</td>\n",
       "      <td>1511</td>\n",
       "      <td>39</td>\n",
       "      <td>897</td>\n",
       "      <td>451</td>\n",
       "      <td>875</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>313</td>\n",
       "      <td>381</td>\n",
       "      <td>20</td>\n",
       "      <td>875.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>475</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1700</td>\n",
       "      <td>433</td>\n",
       "      <td>7</td>\n",
       "      <td>217</td>\n",
       "      <td>93</td>\n",
       "      <td>146</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>385.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>573</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>3198</td>\n",
       "      <td>857</td>\n",
       "      <td>97</td>\n",
       "      <td>470</td>\n",
       "      <td>420</td>\n",
       "      <td>332</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>1314</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>960.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>631</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>4908</td>\n",
       "      <td>1457</td>\n",
       "      <td>30</td>\n",
       "      <td>775</td>\n",
       "      <td>357</td>\n",
       "      <td>249</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  \\\n",
       "1      315    81      7    24   38     39     14    3449    835      69   \n",
       "2      479   130     18    66   72     76      3    1624    457      63   \n",
       "3      496   141     20    65   78     37     11    5628   1575     225   \n",
       "4      321    87     10    39   42     30      2     396    101      12   \n",
       "5      594   169      4    74   51     35     11    4408   1133      19   \n",
       "..     ...   ...    ...   ...  ...    ...    ...     ...    ...     ...   \n",
       "317    497   127      7    65   48     37      5    2703    806      32   \n",
       "318    492   136      5    76   50     94     12    5511   1511      39   \n",
       "319    475   126      3    61   43     52      6    1700    433       7   \n",
       "320    573   144      9    85   60     78      8    3198    857      97   \n",
       "321    631   170      9    77   44     31     11    4908   1457      30   \n",
       "\n",
       "     CRuns  CRBI  CWalks League Division  PutOuts  Assists  Errors  Salary  \\\n",
       "1      321   414     375      N        W      632       43      10   475.0   \n",
       "2      224   266     263      A        W      880       82      14   480.0   \n",
       "3      828   838     354      N        E      200       11       3   500.0   \n",
       "4       48    46      33      N        E      805       40       4    91.5   \n",
       "5      501   336     194      A        W      282      421      25   750.0   \n",
       "..     ...   ...     ...    ...      ...      ...      ...     ...     ...   \n",
       "317    379   311     138      N        E      325        9       3   700.0   \n",
       "318    897   451     875      A        E      313      381      20   875.0   \n",
       "319    217    93     146      A        W       37      113       7   385.0   \n",
       "320    470   420     332      A        E     1314      131      12   960.0   \n",
       "321    775   357     249      A        W      408        4       3  1000.0   \n",
       "\n",
       "    NewLeague  \n",
       "1           N  \n",
       "2           A  \n",
       "3           N  \n",
       "4           N  \n",
       "5           A  \n",
       "..        ...  \n",
       "317         N  \n",
       "318         A  \n",
       "319         A  \n",
       "320         A  \n",
       "321         A  \n",
       "\n",
       "[263 rows x 20 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 20)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=5).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=5, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
       "      random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.81040449,   8.87872786,   7.12487047,  -3.31713488,\n",
       "        -2.01162162,   5.40691525,   7.25828404,  -0.13033385,\n",
       "        -0.25425913,  -0.71109275,   1.81452   ,   0.77083457,\n",
       "        -0.6768975 ,   0.26211894,   0.2646614 ,  -0.36947934,\n",
       "        76.19519054, -90.15523668, -16.00453535])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.4251968687158296"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdalar = 10**np.linspace(10,-2,100)*.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.00000000e+09, 3.78231664e+09, 2.86118383e+09, 2.16438064e+09,\n",
       "       1.63727458e+09, 1.23853818e+09, 9.36908711e+08, 7.08737081e+08,\n",
       "       5.36133611e+08, 4.05565415e+08, 3.06795364e+08, 2.32079442e+08,\n",
       "       1.75559587e+08, 1.32804389e+08, 1.00461650e+08, 7.59955541e+07,\n",
       "       5.74878498e+07, 4.34874501e+07, 3.28966612e+07, 2.48851178e+07,\n",
       "       1.88246790e+07, 1.42401793e+07, 1.07721735e+07, 8.14875417e+06,\n",
       "       6.16423370e+06, 4.66301673e+06, 3.52740116e+06, 2.66834962e+06,\n",
       "       2.01850863e+06, 1.52692775e+06, 1.15506485e+06, 8.73764200e+05,\n",
       "       6.60970574e+05, 5.00000000e+05, 3.78231664e+05, 2.86118383e+05,\n",
       "       2.16438064e+05, 1.63727458e+05, 1.23853818e+05, 9.36908711e+04,\n",
       "       7.08737081e+04, 5.36133611e+04, 4.05565415e+04, 3.06795364e+04,\n",
       "       2.32079442e+04, 1.75559587e+04, 1.32804389e+04, 1.00461650e+04,\n",
       "       7.59955541e+03, 5.74878498e+03, 4.34874501e+03, 3.28966612e+03,\n",
       "       2.48851178e+03, 1.88246790e+03, 1.42401793e+03, 1.07721735e+03,\n",
       "       8.14875417e+02, 6.16423370e+02, 4.66301673e+02, 3.52740116e+02,\n",
       "       2.66834962e+02, 2.01850863e+02, 1.52692775e+02, 1.15506485e+02,\n",
       "       8.73764200e+01, 6.60970574e+01, 5.00000000e+01, 3.78231664e+01,\n",
       "       2.86118383e+01, 2.16438064e+01, 1.63727458e+01, 1.23853818e+01,\n",
       "       9.36908711e+00, 7.08737081e+00, 5.36133611e+00, 4.05565415e+00,\n",
       "       3.06795364e+00, 2.32079442e+00, 1.75559587e+00, 1.32804389e+00,\n",
       "       1.00461650e+00, 7.59955541e-01, 5.74878498e-01, 4.34874501e-01,\n",
       "       3.28966612e-01, 2.48851178e-01, 1.88246790e-01, 1.42401793e-01,\n",
       "       1.07721735e-01, 8.14875417e-02, 6.16423370e-02, 4.66301673e-02,\n",
       "       3.52740116e-02, 2.66834962e-02, 2.01850863e-02, 1.52692775e-02,\n",
       "       1.15506485e-02, 8.73764200e-03, 6.60970574e-03, 5.00000000e-03])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "katsayilar = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lambdalar:\n",
    "    ridge_model.set_params(alpha = i)\n",
    "    ridge_model.fit(x_train, y_train)\n",
    "    katsayilar.append(ridge_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.08705828e-03,  3.59972026e-04,  5.52181027e-05,  1.92813177e-04,\n",
       "         1.96696069e-04,  1.59478501e-04,  2.78199599e-05,  1.78978518e-02,\n",
       "         5.28448603e-03,  6.33684784e-04,  2.78574434e-03,  2.70578331e-03,\n",
       "         1.95710128e-03,  1.87423190e-03,  1.54040667e-04,  2.97933111e-06,\n",
       "         2.39984989e-07, -1.51804510e-06,  3.31089982e-07]),\n",
       " array([ 1.41677983e-03,  4.69820454e-04,  7.18242293e-05,  2.52218183e-04,\n",
       "         2.55763476e-04,  2.07728851e-04,  3.41731833e-05,  2.22675231e-02,\n",
       "         6.58971645e-03,  7.96723486e-04,  3.48283639e-03,  3.38849662e-03,\n",
       "         2.44474193e-03,  2.46055074e-03,  2.00411447e-04,  4.05879985e-06,\n",
       "         3.06791363e-07, -2.00697735e-06,  4.22750663e-07]),\n",
       " array([ 1.84180994e-03,  6.11797854e-04,  9.31516430e-05,  3.29313865e-04,\n",
       "         3.31574150e-04,  2.69862282e-04,  4.11993224e-05,  2.73092348e-02,\n",
       "         8.10613246e-03,  9.90615632e-04,  4.29892819e-03,  4.19154557e-03,\n",
       "         3.01420413e-03,  3.22598807e-03,  2.59998767e-04,  5.54696646e-06,\n",
       "         3.89590845e-07, -2.65335139e-06,  5.35999686e-07]),\n",
       " array([ 2.38835573e-03,  7.94911180e-04,  1.20464748e-04,  4.29197870e-04,\n",
       "         4.28587877e-04,  3.49672945e-04,  4.85735865e-05,  3.29487297e-02,\n",
       "         9.81901671e-03,  1.21671761e-03,  5.23061273e-03,  5.11427511e-03,\n",
       "         3.66208312e-03,  4.22364586e-03,  3.36365620e-04,  7.59686227e-06,\n",
       "         4.91353840e-07, -3.50777634e-06,  6.74604224e-07]),\n",
       " array([ 3.09009626e-03,  1.03077807e-03,  1.55382775e-04,  5.58473604e-04,\n",
       "         5.52508877e-04,  4.52038103e-04,  5.57795062e-05,  3.90401495e-02,\n",
       "         1.16953022e-02,  1.47539158e-03,  6.26651564e-03,  6.14928402e-03,\n",
       "         4.37897884e-03,  5.52205602e-03,  4.34090225e-04,  1.04109479e-05,\n",
       "         6.15653427e-07, -4.63702970e-06,  8.42961127e-07]),\n",
       " array([ 3.99078636e-03,  1.33452564e-03,  2.00008537e-04,  7.25754223e-04,\n",
       "         7.10738029e-04,  5.83304802e-04,  6.21041602e-05,  4.53725039e-02,\n",
       "         1.36860237e-02,  1.76653067e-03,  7.38894131e-03,  7.28417751e-03,\n",
       "         5.15056825e-03,  7.20959605e-03,  5.59142468e-04,  1.42511133e-05,\n",
       "         7.67085867e-07, -6.12914603e-06,  1.04655631e-06]),\n",
       " array([ 5.14774210e-03,  1.72599105e-03,  2.57103265e-04,  9.42329790e-04,\n",
       "         9.12986699e-04,  7.51813035e-04,  6.66592521e-05,  5.16922252e-02,\n",
       "         1.57335162e-02,  2.09064895e-03,  8.57804087e-03,  8.50573034e-03,\n",
       "         5.96044306e-03,  9.39987293e-03,  7.19400260e-04,  1.94483594e-05,\n",
       "         9.51936629e-07, -8.10006447e-06,  1.29268236e-06]),\n",
       " array([ 6.63625037e-03,  2.23124851e-03,  3.30309746e-04,  1.22301529e-03,\n",
       "         1.17205779e-03,  9.68565766e-04,  6.84187693e-05,  5.77371815e-02,\n",
       "         1.77820817e-02,  2.45041949e-03,  9.81789688e-03,  9.80588055e-03,\n",
       "         6.79427058e-03,  1.22378921e-02,  9.25318808e-04,  2.64114755e-05,\n",
       "         1.17910270e-06, -1.07022908e-05,  1.59137023e-06]),\n",
       " array([ 8.55483745e-03,  2.88445935e-03,  4.24420527e-04,  1.58718502e-03,\n",
       "         1.50477879e-03,  1.24804330e-03,  6.62540589e-05,  6.32720806e-02,\n",
       "         1.97893052e-02,  2.85238338e-03,  1.11031502e-02,  1.11882336e-02,\n",
       "         7.64428385e-03,  1.59064960e-02,  1.19075375e-03,  3.56332379e-05,\n",
       "         1.46126190e-06, -1.41361477e-05,  1.95642271e-06]),\n",
       " array([ 1.10312454e-02,  3.73002061e-03,  5.45684591e-04,  2.05998878e-03,\n",
       "         1.93305764e-03,  1.60915216e-03,  5.89463545e-05,  6.81144258e-02,\n",
       "         2.17349754e-02,  3.30852528e-03,  1.24446956e-02,  1.26736367e-02,\n",
       "         8.51303131e-03,  2.06320735e-02,  1.53393253e-03,  4.76905218e-05,\n",
       "         1.81630840e-06, -1.86643235e-05,  2.40641302e-06]),\n",
       " array([ 1.42288809e-02,  4.82496917e-03,  7.02143825e-04,  2.67373455e-03,\n",
       "         2.48502252e-03,  2.07629541e-03,  4.51663040e-05,  7.21446369e-02,\n",
       "         2.36258289e-02,  3.83753128e-03,  1.38736179e-02,  1.43039512e-02,\n",
       "         9.41577138e-03,  2.66878486e-02,  1.97856321e-03,  6.32307599e-05,\n",
       "         2.26916665e-06, -2.46305879e-05,  2.96553891e-06]),\n",
       " array([ 1.83533492e-02,  6.24156186e-03,  9.03986475e-04,  3.46940075e-03,\n",
       "         3.19618820e-03,  2.68054308e-03,  2.34244013e-05,  7.53005841e-02,\n",
       "         2.54962052e-02,  4.46571897e-03,  1.54434962e-02,  1.61439894e-02,\n",
       "         1.03815693e-02,  3.43920784e-02,  2.55505046e-03,  8.29312258e-05,\n",
       "         2.85425312e-06, -3.24837353e-05,  3.66428247e-06]),\n",
       " array([ 2.36583931e-02,  8.06987606e-03,  1.16389452e-03,  4.49819833e-03,\n",
       "         4.11055071e-03,  3.46085782e-03, -7.99178240e-06,  7.75617205e-02,\n",
       "         2.74060905e-02,  5.22774181e-03,  1.72319022e-02,  1.82821668e-02,\n",
       "         1.14536429e-02,  4.40972790e-02,  3.30173084e-03,  1.07409746e-04,\n",
       "         3.61908966e-06, -4.28080520e-05,  4.53991031e-06]),\n",
       " array([ 3.04501016e-02,  1.04201578e-02,  1.49734514e-03,  5.82303756e-03,\n",
       "         5.28144612e-03,  4.46529082e-03, -5.10715931e-05,  7.89293976e-02,\n",
       "         2.94384183e-02,  6.16716441e-03,  1.93421004e-02,  2.08305107e-02,\n",
       "         1.26896156e-02,  5.61654836e-02,  4.26591900e-03,  1.37056133e-04,\n",
       "         4.62994572e-06, -5.63619514e-05,  5.63701574e-06]),\n",
       " array([ 3.90877335e-02,  1.34245129e-02,  1.92280724e-03,  7.51967840e-03,\n",
       "         6.77193714e-03,  5.75201908e-03, -1.08103747e-04,  7.94085363e-02,\n",
       "         3.16971295e-02,  7.33690583e-03,  2.19057141e-02,  2.39243876e-02,\n",
       "         1.41621442e-02,  7.09243460e-02,  5.50434864e-03,  1.71744357e-04,\n",
       "         5.98103051e-06, -7.41269482e-05,  7.00870479e-06]),\n",
       " array([ 4.99790908e-02,  1.72374527e-02,  2.46176162e-03,  9.67728453e-03,\n",
       "         8.65444650e-03,  7.39007141e-03, -1.81647005e-04,  7.89933590e-02,\n",
       "         3.43069156e-02,  8.79941161e-03,  2.50867048e-02,  2.77219584e-02,\n",
       "         1.59600508e-02,  8.86010366e-02,  7.08228283e-03,  2.10379504e-04,\n",
       "         7.80986903e-06, -9.73700195e-05,  8.71990580e-06]),\n",
       " array([ 6.35683184e-02,  2.20348389e-02,  3.13847615e-03,  1.23980931e-02,\n",
       "         1.10093810e-02,  9.45961578e-03, -2.74433813e-04,  7.76577086e-02,\n",
       "         3.74152151e-02,  1.06262815e-02,  2.90865964e-02,  3.24031662e-02,\n",
       "         1.81897361e-02,  1.09236939e-01,  9.07018129e-03,  2.50236073e-04,\n",
       "         1.03233178e-05, -1.27723784e-04,  1.08559283e-05]),\n",
       " array([ 8.03144193e-02,  2.80109646e-02,  3.97948810e-03,  1.57959666e-02,\n",
       "         1.39225986e-02,  1.20517651e-02, -3.89198631e-04,  7.53491228e-02,\n",
       "         4.11970425e-02,  1.28969399e-02,  3.41504870e-02,  3.81680540e-02,\n",
       "         2.09762607e-02,  1.32596777e-01,  1.15364715e-02,  2.86060551e-04,\n",
       "         1.38414001e-05, -1.67290929e-04,  1.35420021e-05]),\n",
       " array([ 1.00659415e-01,  3.53737763e-02,  5.01276201e-03,  1.99936664e-02,\n",
       "         1.74817046e-02,  1.52679591e-02, -5.28428627e-04,  7.19852765e-02,\n",
       "         4.58634610e-02,  1.56957180e-02,  4.05729409e-02,  4.52341750e-02,\n",
       "         2.44629669e-02,  1.58098532e-01,  1.45349889e-02,  3.08943729e-04,\n",
       "         1.88697449e-05, -2.18781763e-04,  1.69829249e-05]),\n",
       " array([ 1.24985300e-01,  4.43383743e-02,  6.26646135e-03,  2.51186578e-02,\n",
       "         2.17711724e-02,  1.92189991e-02, -6.94031851e-04,  6.74515998e-02,\n",
       "         5.16745666e-02,  1.91063111e-02,  4.87021870e-02,  5.38323815e-02,\n",
       "         2.88077603e-02,  1.84798490e-01,  1.80865855e-02,  3.05013003e-04,\n",
       "         2.62154267e-05, -2.85696212e-04,  2.15353352e-05]),\n",
       " array([ 1.53558197e-01,  5.51187291e-02,  7.76715884e-03,  3.12970555e-02,\n",
       "         2.68660409e-02,  2.40236617e-02, -8.86898780e-04,  6.15998145e-02,\n",
       "         5.89572171e-02,  2.32019817e-02,  5.89401216e-02,  6.41990135e-02,\n",
       "         3.41732141e-02,  2.11459552e-01,  2.21569148e-02,  2.54044649e-04,\n",
       "         3.71643214e-05, -3.72563522e-04,  2.78270230e-05]),\n",
       " array([ 1.86457341e-01,  6.79172663e-02,  9.53716658e-03,  3.86451070e-02,\n",
       "         3.28235831e-02,  2.98066321e-02, -1.10629915e-03,  5.42486226e-02,\n",
       "         6.81259518e-02,  2.80294254e-02,  7.17346292e-02,  7.65608732e-02,\n",
       "         4.07069956e-02,  2.36706263e-01,  2.66367239e-02,  1.28145040e-04,\n",
       "         5.37390333e-05, -4.85254784e-04,  3.69363946e-05]),\n",
       " array([ 2.23488679e-01,  8.29124771e-02,  1.15906901e-02,  4.72579656e-02,\n",
       "         3.96724511e-02,  3.66957155e-02, -1.34902777e-03,  4.51891944e-02,\n",
       "         7.97025208e-02,  3.35848087e-02,  8.75603655e-02,  9.11090818e-02,\n",
       "         4.85098565e-02,  2.59234910e-01,  3.13359801e-02, -1.09311057e-04,\n",
       "         7.90531634e-05, -6.31387074e-04,  5.06394947e-05]),\n",
       " array([ 2.64091406e-01,  1.00247072e-01,  1.39289695e-02,  5.71971039e-02,\n",
       "         4.74001434e-02,  4.48194982e-02, -1.60821935e-03,  3.41983905e-02,\n",
       "         9.43255889e-02,  3.97832322e-02,  1.06885319e-01,  1.07961438e-01,\n",
       "         5.75920571e-02,  2.78020879e-01,  3.60055069e-02, -5.04310897e-04,\n",
       "         1.17769153e-04, -8.20846578e-04,  7.17218276e-05]),\n",
       " array([ 3.07259930e-01,  1.20023291e-01,  1.65355470e-02,  6.84805408e-02,\n",
       "         5.59422985e-02,  5.43089014e-02, -1.87179996e-03,  2.10611519e-02,\n",
       "         1.12738462e-01,  4.64280598e-02,  1.30123747e-01,  1.27121136e-01,\n",
       "         6.78260905e-02,  2.92464684e-01,  4.03947313e-02, -1.11239332e-03,\n",
       "         1.76654795e-04, -1.06647321e-03,  1.04339598e-04]),\n",
       " array([ 3.51515911e-01,  1.42315715e-01,  1.93739007e-02,  8.10827983e-02,\n",
       "         6.51800228e-02,  6.53084038e-02, -2.12059533e-03,  5.60078488e-03,\n",
       "         1.35740789e-01,  5.31920946e-02,  1.57580614e-01,  1.48449082e-01,\n",
       "         7.89114962e-02,  3.02442388e-01,  4.43389399e-02, -1.99879194e-03,\n",
       "         2.65224510e-04, -1.38496929e-03,  1.54405607e-04]),\n",
       " array([ 3.94963670e-01,  1.67212044e-01,  2.23900744e-02,  9.49519148e-02,\n",
       "         7.49518524e-02,  7.80032771e-02, -2.32611607e-03, -1.22861853e-02,\n",
       "         1.64092518e-01,  5.96238619e-02,  1.89396119e-01,  1.71669244e-01,\n",
       "         9.03706006e-02,  3.08260068e-01,  4.78484595e-02, -3.23949414e-03,\n",
       "         3.96457704e-04, -1.79811559e-03,  2.29979158e-04]),\n",
       " array([ 4.35440787e-01,  1.94886967e-01,  2.55218451e-02,  1.10047299e-01,\n",
       "         8.50833041e-02,  9.26665587e-02, -2.44796656e-03, -3.25937122e-02,\n",
       "         1.98367303e-01,  6.51849964e-02,  2.25498900e-01,  1.96414281e-01,\n",
       "         1.01586618e-01,  3.10538783e-01,  5.11581599e-02, -4.92458797e-03,\n",
       "         5.87619775e-04, -2.33439666e-03,  3.41667593e-04]),\n",
       " array([ 0.4707398 ,  0.22570501,  0.02871347,  0.12639534,  0.09542999,\n",
       "         0.10972413, -0.00243074, -0.05516994,  0.23876852,  0.06931006,\n",
       "         0.26557372,  0.2222951 ,  0.11187863,  0.31006874,  0.05470242,\n",
       "        -0.00716513,  0.00086127, -0.00303116,  0.0005031 ]),\n",
       " array([ 0.49884358,  0.26033979,  0.03193236,  0.14415252,  0.10592353,\n",
       "         0.12983066, -0.00220023, -0.07968271,  0.28494095,  0.07146667,\n",
       "         0.30904807,  0.24895963,  0.12059091,  0.30767017,  0.05901068,\n",
       "        -0.01010398,  0.00124662, -0.00393745,  0.0007316 ]),\n",
       " array([ 0.51810441,  0.29989425,  0.03518278,  0.16366201,  0.11660696,\n",
       "         0.15394607, -0.00165906, -0.10559393,  0.33582833,  0.07119222,\n",
       "         0.35510609,  0.27611091,  0.12716769,  0.30408785,  0.06455753,\n",
       "        -0.01392994,  0.00178144, -0.00511776,  0.00104922]),\n",
       " array([ 0.52731238,  0.34600997,  0.0385126 ,  0.18549005,  0.1276497 ,\n",
       "         0.18340272, -0.00068181, -0.13215709,  0.38963232,  0.06809583,\n",
       "         0.40274434,  0.30348383,  0.13119077,  0.29993061,  0.07162596,\n",
       "        -0.01889366,  0.00251475, -0.0066569 ,  0.00148436]),\n",
       " array([ 0.52563557,  0.40096129,  0.04201125,  0.21043195,  0.13933819,\n",
       "         0.21995563,  0.00088985, -0.15845442,  0.44391197,  0.06183284,\n",
       "         0.45088281,  0.33080995,  0.13237205,  0.2956528 ,  0.08023781,\n",
       "        -0.02532345,  0.00351064, -0.00866639,  0.00207418]),\n",
       " array([ 0.51245689,  0.46773416,  0.04579935,  0.23947869,  0.15204364,\n",
       "         0.26581035,  0.00325215, -0.18347884,  0.49582229,  0.05207147,\n",
       "         0.49852755,  0.35780758,  0.13050722,  0.29156508,  0.09017435,\n",
       "        -0.03363913,  0.00485343, -0.01129272,  0.00286803]),\n",
       " array([ 0.48716485,  0.55008855,  0.05001106,  0.27373331,  0.16616941,\n",
       "         0.32362115,  0.00664439, -0.20624638,  0.54243844,  0.03847238,\n",
       "         0.54495307,  0.38421156,  0.1254093 ,  0.28786002,  0.10106927,\n",
       "        -0.04436196,  0.00665481, -0.01472784,  0.00393228]),\n",
       " array([ 0.4489693 ,  0.65259294,  0.0547705 ,  0.31425899,  0.18207896,\n",
       "         0.39644748,  0.01135508, -0.22590778,  0.58107838,  0.02069636,\n",
       "         0.58985146,  0.40982593,  0.11684682,  0.28464147,  0.11252912,\n",
       "        -0.05811777,  0.00906349, -0.01922258,  0.00535701]),\n",
       " array([ 0.3968063 ,  0.78060342,  0.06016408,  0.36183375,  0.20000384,\n",
       "         0.48764781,  0.01772912, -0.24182798,  0.60954426, -0.00155238,\n",
       "         0.63339787,  0.4345655 ,  0.10451029,  0.28195087,  0.12423297,\n",
       "        -0.07562832,  0.01227822, -0.02510361,  0.00726512]),\n",
       " array([ 0.32937467,  0.9401416 ,  0.06621354,  0.41658487,  0.21993467,\n",
       "         0.60068406,  0.02617569, -0.25361874,  0.62624781, -0.02844544,\n",
       "         0.67621095,  0.45845871,  0.0880216 ,  0.27978824,  0.13598169,\n",
       "        -0.09768359,  0.01656543, -0.03279487,  0.00982478]),\n",
       " array([ 0.24531948,  1.13761151,  0.07286178,  0.4774922 ,  0.2415094 ,\n",
       "         0.73881463,  0.03717582, -0.2611302 ,  0.63023671, -0.05991964,\n",
       "         0.71922379,  0.48160498,  0.06698821,  0.27812741,  0.1476926 ,\n",
       "        -0.12508529,  0.02228264, -0.04284536,  0.01326611]),\n",
       " array([ 0.1435482 ,  1.37929734,  0.07999484,  0.54179368,  0.26393219,\n",
       "         0.90467818,  0.05128863, -0.26442052,  0.62116703, -0.0955613 ,\n",
       "         0.76350787,  0.50410208,  0.04109169,  0.27692596,  0.15935413,\n",
       "        -0.15855204,  0.02990935, -0.05596537,  0.0179032 ]),\n",
       " array([ 0.02363255,  1.67061387,  0.08753565,  0.60440494,  0.28597299,\n",
       "         1.09981641,  0.06915608, -0.26372195,  0.59926001, -0.13453482,\n",
       "         0.81009977,  0.52597367,  0.01019011,  0.27613096,  0.17096354,\n",
       "        -0.19858115,  0.04008731, -0.07307487,  0.0241626 ]),\n",
       " array([-0.11378671,  2.01514908,  0.09564972,  0.65756367,  0.30609314,\n",
       "         1.32423652,  0.0915081 , -0.2594123 ,  0.56525502, -0.17562381,\n",
       "         0.85987142,  0.54713291, -0.02559235,  0.27568181,  0.18246959,\n",
       "        -0.2452718 ,  0.05367214, -0.09536904,  0.0326191 ]),\n",
       " array([-0.26670385,  2.41363844,  0.10508862,  0.69098126,  0.32269376,\n",
       "         1.57613996,  0.11917122, -0.25199043,  0.52034556, -0.21743938,\n",
       "         0.91346331,  0.56741057, -0.06581575,  0.27551143,  0.19373753,\n",
       "        -0.29813006,  0.07179912, -0.12440747,  0.04403999]),\n",
       " array([-0.43167285,  2.86310628,  0.11765572,  0.6927572 ,  0.33439715,\n",
       "         1.85191019,  0.15308516, -0.24204868,  0.46608227, -0.25878513,\n",
       "         0.97127119,  0.58665136, -0.10973206,  0.2755476 ,  0.20454612,\n",
       "        -0.35589354,  0.09596621, -0.16223522,  0.05943915]),\n",
       " array([-0.6040179 ,  3.35644666,  0.13671717,  0.65112408,  0.34019682,\n",
       "         2.14635766,  0.19433224, -0.23023687,  0.40424807, -0.29906764,\n",
       "         1.03344795,  0.60484538, -0.15634765,  0.27571572,  0.21461709,\n",
       "        -0.41642724,  0.12813948, -0.21154533,  0.0801436 ]),\n",
       " array([-0.77830722,  3.88264504,  0.16761906,  0.55675758,  0.33933019,\n",
       "         2.45312403,  0.24418475, -0.21721953,  0.33673633, -0.3385693 ,\n",
       "         1.09987502,  0.62223123, -0.20451768,  0.27594368,  0.2236679 ,\n",
       "        -0.47674786,  0.17088798, -0.27589485,  0.10787726]),\n",
       " array([-0.94897769,  4.42767568,  0.21783329,  0.40503507,  0.33087526,\n",
       "         2.76512455,  0.30417652, -0.20363305,  0.26546633, -0.37843093,\n",
       "         1.17008688,  0.63931124, -0.25304248,  0.27616801,  0.23147139,\n",
       "        -0.53322691,  0.22755856, -0.35998977,  0.14486916]),\n",
       " array([-1.11095288,  4.97592285,  0.29665745,  0.19746729,  0.31327399,\n",
       "         3.07497739,  0.37620355, -0.19005043,  0.19234109, -0.42032842,\n",
       "         1.24318757,  0.65676164, -0.30074808,  0.27633977,  0.23790421,\n",
       "        -0.58199675,  0.3025042 , -0.47005898,  0.19399524]),\n",
       " array([-1.26011918,  5.51184871,  0.4143498 , -0.05827957,  0.28409378,\n",
       "         3.37545591,  0.46264872, -0.17695715,  0.11921725, -0.46597955,\n",
       "         1.31783559,  0.67527456, -0.34655253,  0.27642815,  0.24297057,\n",
       "        -0.61952664,  0.40138114, -0.61434165,  0.25896264]),\n",
       " array([-1.39359306,  6.02159062,  0.58069505, -0.34983106,  0.24025666,\n",
       "         3.66000488,  0.56650459, -0.16473766,  0.04784951, -0.51667315,\n",
       "         1.39235321,  0.69539447, -0.389528  ,  0.27642056,  0.24679657,\n",
       "        -0.64325304,  0.5315299 , -0.80371445,  0.34454253]),\n",
       " array([-1.5097815 ,  6.49419307,  0.80316402, -0.66248462,  0.17873841,\n",
       "         3.9232733 ,  0.69144007, -0.15367066, -0.02019658, -0.57295067,\n",
       "         1.46494569,  0.71739679, -0.42895941,  0.27631954,  0.24959917,\n",
       "        -0.6520776 ,  0.70245206, -1.05248262,  0.45685054]),\n",
       " array([-1.60827968,  6.92225972,  1.0850129 , -0.98166033,  0.09750881,\n",
       "         4.16152392,  0.84173537, -0.14393249, -0.08363246, -0.63446354,\n",
       "         1.5339501 ,  0.74122336, -0.46438666,  0.2761376 ,  0.2516403 ,\n",
       "        -0.64655042,  0.92638753, -1.37935217,  0.60366354]),\n",
       " array([-1.68966187e+00,  7.30195969e+00,  1.42381149e+00, -1.29468666e+00,\n",
       "        -3.62900944e-03,  4.37278186e+00,  1.02201054e+00, -1.35608227e-01,\n",
       "        -1.41494723e-01, -6.99968600e-01,  1.59802280e+00,  7.66468354e-01,\n",
       "        -4.95614137e-01,  2.75891667e-01,  2.53178738e-01, -6.28664546e-01,\n",
       "         1.21898388e+00, -1.80858680e+00,  7.94743507e-01]),\n",
       " array([-1.75521934,  7.63250922,  1.810921  , -1.59163889, -0.12260881,\n",
       "         4.55668845,  1.23670227, -0.12870825, -0.19313812, -0.76742926,\n",
       "         1.65621877,  0.79240809, -0.52268312,  0.27559826,  0.25443116,\n",
       "        -0.60134741,  1.60002415, -2.37132894,  1.04210968]),\n",
       " array([-1.80669081,  7.91538656,  2.23228563, -1.86540884, -0.25524844,\n",
       "         4.71414786,  1.4893048 , -0.12318631, -0.23819186, -0.83422019,\n",
       "         1.70797608,  0.81807576, -0.54581766,  0.27526998,  0.25554995,\n",
       "        -0.56784719,  2.09413745, -3.10702231,  1.36015201]),\n",
       " array([-1.8460197 ,  8.15355087,  2.67052913, -2.11139641, -0.39594744,\n",
       "         4.84691116,  1.7814807 , -0.11895504, -0.2765114 , -0.89743421,\n",
       "         1.75305172,  0.84237965, -0.56536284,  0.27491346,  0.25661944,\n",
       "        -0.53121227,  2.73135033, -4.06480085,  1.76540696]),\n",
       " array([-1.87515919,  8.35083325,  3.107865  , -2.32714395, -0.53872158,\n",
       "         4.95721543,  2.11225087, -0.115897  , -0.30814612, -0.95425156,\n",
       "         1.79145062,  0.8642477 , -0.58173065,  0.27452851,  0.2576669 ,\n",
       "        -0.49397252,  3.5472491 , -5.30458807,  2.27572284]),\n",
       " array([-1.89593262,  8.51152795,  3.52898445, -2.51203537, -0.67825363,\n",
       "         5.04752698,  2.47754217, -0.11387258, -0.33332037, -1.00228798,\n",
       "         1.82336571,  0.88276469, -0.59535973,  0.27410836,  0.25868123,\n",
       "        -0.45802465,  4.5824306 , -6.89746573,  2.9084461 ]),\n",
       " array([-1.90994639,  8.64011983,  3.92310473, -2.66702658, -0.81066339,\n",
       "         5.12038018,  2.87033297, -0.11272745, -0.3524116 , -1.03983364,\n",
       "         1.84912635,  0.89726768, -0.60668768,  0.2736409 ,  0.25963217,\n",
       "        -0.42465708,  5.88086742, -8.92461954,  3.67721061]),\n",
       " array([ -1.9185465 ,   8.74107098,   4.28473642,  -2.79433964,\n",
       "         -0.9338395 ,   5.17828063,   3.28144629,  -0.11230164,\n",
       "         -0.36591278,  -1.06594   ,   1.86914816,   0.90738272,\n",
       "         -0.61613119,   0.27311095,   0.26048537,  -0.39463809,\n",
       "          7.48688573, -11.47390082,   4.58699972]),\n",
       " array([ -1.92280945,   8.81862902,   4.61322124,  -2.89710054,\n",
       "         -1.0473443 ,   5.22364529,   3.70075885,  -0.11244021,\n",
       "         -0.3743809 ,  -1.08037534,   1.88388412,   0.91301087,\n",
       "         -0.62407042,   0.27250335,   0.26121161,  -0.36831577,\n",
       "          9.44075517, -14.63288659,   5.62749321]),\n",
       " array([ -1.92356056,   8.87666466,   4.91143543,  -2.97895449,\n",
       "         -1.15201594,   5.25876301,   4.1183964 ,  -0.11300313,\n",
       "         -0.37838604,  -1.08351161,   1.89378531,   0.9142872 ,\n",
       "         -0.63083652,   0.27180653,   0.26179136,  -0.34571301,\n",
       "         11.77349146, -18.47751473,   6.76539754]),\n",
       " array([ -1.92141509,   8.91856616,   5.18414497,  -3.04370749,\n",
       "         -1.24942102,   5.28576369,   4.52552842,  -0.11387199,\n",
       "         -0.37847759,  -1.07620488,   1.89928279,   0.9115363 ,\n",
       "         -0.63670275,   0.2710162 ,   0.26221639,  -0.32662596,\n",
       "         14.50228148, -23.05623072,   7.93741531]),\n",
       " array([ -1.9168372 ,   8.94720973,   5.43641484,  -3.09502361,\n",
       "         -1.34128685,   5.3065845 ,   4.91465054,  -0.11495231,\n",
       "         -0.37517654,  -1.05970019,   1.90079754,   0.90523597,\n",
       "         -0.64188083,   0.2701382 ,   0.26249027,  -0.31073979,\n",
       "         17.62856776, -28.37133375,   9.04636776]),\n",
       " array([ -1.91020764,   8.96500212,   5.67234167,  -3.13618385,\n",
       "         -1.42900845,   5.322925  ,   5.27955004,  -0.11617225,\n",
       "         -0.3689901 ,  -1.03555364,   1.8987753 ,   0.89598626,\n",
       "         -0.64652367,   0.26918984,   0.2626287 ,  -0.29776325,\n",
       "         21.14061583, -34.36165434,   9.96309192]),\n",
       " array([ -1.9018865 ,   8.97396885,   5.89427279,  -3.1699073 ,\n",
       "         -1.51330506,   5.33619318,   5.61526783,  -0.11747948,\n",
       "         -0.36043415,  -1.00554354,   1.89373069,   0.88447345,\n",
       "         -0.65073445,   0.26819911,   0.2626597 ,  -0.28756179,\n",
       "         25.02082282, -40.89283183,  10.53556402]),\n",
       " array([ -1.8922552 ,   8.97585015,   6.10259019,  -3.19824669,\n",
       "         -1.59408394,   5.34745951,   5.91823878,  -0.11883796,\n",
       "         -0.35004602,  -0.97154793,   1.8862764 ,   0.87142105,\n",
       "         -0.65458032,   0.26720152,   0.26262266,  -0.28024984,\n",
       "         29.25541136, -47.76155677,  10.6044871 ]),\n",
       " array([ -1.88172685,   8.9721717 ,   6.29603819,  -3.22257863,\n",
       "         -1.67053515,   5.35744342,   6.18654873,  -0.12022504,\n",
       "         -0.33837543,  -0.93539098,   1.87711554,   0.85752944,\n",
       "         -0.65810715,   0.26623519,   0.26256519,  -0.27620138,\n",
       "         33.84186587, -54.71675408,  10.02251324]),\n",
       " array([ -1.87072564,   8.96427673,   6.47244819,  -3.24369538,\n",
       "         -1.74141952,   5.36654802,   6.42009476,  -0.12162856,\n",
       "         -0.3259544 ,  -0.89868802,   1.86699113,   0.84341625,\n",
       "         -0.66135151,   0.2653354 ,   0.26253754,  -0.27596038,\n",
       "         38.78918874, -61.4943233 ,   8.673658  ]),\n",
       " array([ -1.85964908,   8.95332991,   6.62960686,  -3.26197325,\n",
       "         -1.80544929,   5.37493759,   6.62047039,  -0.12304314,\n",
       "         -0.3132593 ,  -0.86273123,   1.85660844,   0.82957352,\n",
       "         -0.6643471 ,   0.26452985,   0.26258525,  -0.28006946,\n",
       "         44.10843684, -67.8558909 ,   6.49041872]),\n",
       " array([ -1.8488328 ,   8.94031682,   6.76599454,  -3.27756575,\n",
       "         -1.86163425,   5.38263336,   6.79055551,  -0.12446563,\n",
       "         -0.30068277,  -0.82844672,   1.84655905,   0.81635288,\n",
       "         -0.66712531,   0.26383594,   0.26274191,  -0.28886809,\n",
       "         49.79512404, -73.62002534,   3.46727923]),\n",
       " array([ -1.83853302,   8.92605782,   6.88120801,  -3.29056742,\n",
       "         -1.90949634,   5.38959863,   6.93393754,  -0.12589019,\n",
       "         -0.28852654,  -0.79642622,   1.83727272,   0.80397943,\n",
       "         -0.66971175,   0.26326004,   0.26302387,  -0.3023224 ,\n",
       "         55.80914591, -78.67794982,  -0.33080214]),\n",
       " array([ -1.82892927,   8.91123827,   6.97602686,  -3.30111624,\n",
       "         -1.94912136,   5.3957956 ,   7.05434244,  -0.12730447,\n",
       "         -0.27701409,  -0.76700798,   1.82900728,   0.7925838 ,\n",
       "         -0.67212183,   0.26279885,   0.26342829,  -0.31993817,\n",
       "         62.06019241, -82.99251808,  -4.76760501]),\n",
       " array([ -1.82013957,   8.89644106,   7.05220527,  -3.30943185,\n",
       "         -1.98107762,   5.40121196,   7.15521511,  -0.12868815,\n",
       "         -0.26631147,  -0.74036794,   1.82187009,   0.78223736,\n",
       "         -0.6743585 ,   0.26244179,   0.26393489,  -0.34078382,\n",
       "         68.40592996, -86.58497542,  -9.64589406]),\n",
       " array([ -1.81223659,   8.88216502,   7.11212329,  -3.31580617,\n",
       "         -2.00626147,   5.40586611,   7.23950667,  -0.13001458,\n",
       "         -0.25654371,  -0.71658759,   1.81585603,   0.77297757,\n",
       "         -0.67641368,   0.26217392,   0.26451098,  -0.36361883,\n",
       "         74.66612748, -89.51629481, -14.73005735]),\n",
       " array([ -1.80525773,   8.86882244,   7.15842076,  -3.32056982,\n",
       "         -2.02572792,   5.40980189,   7.30964794,  -0.13125507,\n",
       "         -0.24780017,  -0.6956852 ,   1.81088769,   0.76481873,\n",
       "         -0.67827327,   0.26197859,   0.26511835,  -0.38709127,\n",
       "         80.64955348, -91.86889443, -19.77787797]),\n",
       " array([ -1.79920825,   8.85672296,   7.19369451,  -3.32405395,\n",
       "         -2.04054656,   5.41308056,   7.36763964,  -0.13238414,\n",
       "         -0.240131  ,  -0.6776179 ,   1.80684908,   0.75775145,\n",
       "         -0.67992366,   0.26183963,   0.2657202 ,  -0.40994665,\n",
       "         86.18494577, -93.73207465, -24.57357986]),\n",
       " array([ -1.79406187,   8.84605857,   7.22029406,  -3.32655991,\n",
       "         -2.05170136,   5.41577356,   7.41517936,  -0.13338387,\n",
       "         -0.23354184,  -0.66227339,   1.80360973,   0.75173836,\n",
       "         -0.68135748,   0.26174274,   0.26628654,  -0.43119   ,\n",
       "         91.14591671, -95.19217684, -28.95307797]),\n",
       " array([ -1.78976306,   8.83690199,   7.24021679,  -3.32834172,\n",
       "         -2.06003641,   5.41795666,   7.45376709,  -0.13424612,\n",
       "         -0.22799326,  -0.64946793,   1.80104019,   0.74671281,\n",
       "         -0.6825766 ,   0.26167617,   0.26679692,  -0.45016675,\n",
       "         95.463099  , -96.32699505, -32.81562242]),\n",
       " array([ -1.78623299,   8.82922177,   7.25508225,  -3.32960072,\n",
       "         -2.06623906,   5.41970537,   7.48476496,  -0.1349722 ,\n",
       "         -0.22340746,  -0.63895756,   1.79902077,   0.74258307,\n",
       "         -0.68359234,   0.26163086,   0.26724066,  -0.46656117,\n",
       "         99.12270867, -97.2033658 , -36.12157378]),\n",
       " array([ -1.7833782 ,   8.82290913,   7.26615816,  -3.33048896,\n",
       "         -2.07084791,   5.42109133,   7.509416  ,  -0.13557094,\n",
       "         -0.21968008,  -0.63045984,   1.79744589,   0.739241  ,\n",
       "         -0.68442333,   0.26160015,   0.26761525,  -0.48033703,\n",
       "        102.15545096, -97.87681855, -38.88050737]),\n",
       " array([ -1.78109993,   8.81780859,   7.27441217,  -3.33111713,\n",
       "         -2.07427357,   5.42217975,   7.5288397 ,  -0.13605601,\n",
       "         -0.21669368,  -0.6236789 ,   1.7962255 ,   0.73657218,\n",
       "         -0.68509255,   0.26157929,   0.26792401,  -0.49165312,\n",
       "        104.62138682, -98.39238568, -41.13535508]),\n",
       " array([ -1.77930191,   8.81374517,   7.28057067,  -3.33156368,\n",
       "         -2.07682349,   5.42302793,   7.54402153,  -0.13644325,\n",
       "         -0.21432963,  -0.61832752,   1.79528467,   0.7344648 ,\n",
       "         -0.68562444,   0.26156506,   0.26817367,  -0.5007805 ,\n",
       "        106.59540858, -98.78594571, -42.94724371]),\n",
       " array([ -1.77789585,   8.81054479,   7.28517355,  -3.33188334,\n",
       "         -2.07872539,   5.42368469,   7.55580725,  -0.13674874,\n",
       "         -0.21247661,  -0.61414271,   1.79456241,   0.7328161 ,\n",
       "         -0.68604264,   0.26155527,   0.26837251,  -0.5080364 ,\n",
       "        108.15589045, -99.08571269, -44.38358387]),\n",
       " array([ -1.7768044 ,   8.80804703,   7.28862022,  -3.33211392,\n",
       "         -2.08014706,   5.42419062,   7.56490537,  -0.13698747,\n",
       "         -0.21103564,  -0.61089419,   1.79400976,   0.73153586,\n",
       "         -0.68636864,   0.26154846,   0.268529  ,  -0.51373905,\n",
       "        109.37719305, -99.31365911, -45.51008002]),\n",
       " array([ -1.77596212,   8.80611157,   7.29120578,  -3.33228154,\n",
       "         -2.08121201,   5.42457876,   7.57189709,  -0.13717263,\n",
       "         -0.20992213,  -0.60838725,   1.79358801,   0.73054761,\n",
       "         -0.68662101,   0.26154367,   0.26865103,  -0.51818117,\n",
       "        110.32555799, -99.48677333, -46.38619364]),\n",
       " array([ -1.77531513,   8.80462022,   7.29314852,  -3.33240426,\n",
       "         -2.08201127,   5.42487557,   7.57725081,  -0.13731541,\n",
       "         -0.2090659 ,  -0.60646148,   1.7932668 ,   0.72978833,\n",
       "         -0.68681534,   0.26154026,   0.2687455 ,  -0.52161761,\n",
       "        111.05748828, -99.61811926, -47.06315392]),\n",
       " array([ -1.77481992,   8.80347606,   7.29461029,  -3.33249467,\n",
       "         -2.0826121 ,   5.42510197,   7.58133874,  -0.13742502,\n",
       "         -0.20841002,  -0.60498748,   1.79302257,   0.72920707,\n",
       "         -0.68696435,   0.2615378 ,   0.26881824,  -0.52426193,\n",
       "        111.61971017, -99.71770228, -47.5836089 ]),\n",
       " array([ -1.77444193,   8.80260119,   7.29571143,  -3.33256165,\n",
       "         -2.08306438,   5.42527432,   7.58445333,  -0.13750886,\n",
       "         -0.20790911,  -0.60386238,   1.79283708,   0.72876336,\n",
       "         -0.68707825,   0.26153602,   0.26887401,  -0.52628845,\n",
       "        112.05000242, -99.79316204, -47.98219881]),\n",
       " array([ -1.77415404,   8.80193394,   7.29654169,  -3.33261149,\n",
       "         -2.0834052 ,   5.42540533,   7.5868223 ,  -0.13757282,\n",
       "         -0.20752741,  -0.60300544,   1.79269635,   0.72842537,\n",
       "         -0.6871651 ,   0.26153472,   0.26891663,  -0.52783666,\n",
       "        112.3784051 , -99.85031844, -48.28655768]),\n",
       " array([ -1.77393513,   8.80142605,   7.29716817,  -3.33264871,\n",
       "         -2.08366225,   5.4255048 ,   7.58862182,  -0.13762153,\n",
       "         -0.20723707,  -0.60235381,   1.79258964,   0.72816834,\n",
       "         -0.68723119,   0.26153376,   0.26894912,  -0.52901664,\n",
       "        112.62851072, -99.89359748, -48.5184391 ]),\n",
       " array([ -1.77376887,   8.80104004,   7.29764116,  -3.33267659,\n",
       "         -2.08385626,   5.42558026,   7.5899874 ,  -0.13765855,\n",
       "         -0.20701651,  -0.60185892,   1.79250878,   0.72797313,\n",
       "         -0.68728141,   0.26153305,   0.26897385,  -0.52991435,\n",
       "        112.81867726, -99.92636072, -48.69479898]),\n",
       " array([ -1.77364273,   8.80074698,   7.29799843,  -3.33269751,\n",
       "         -2.08400277,   5.42563746,   7.59102289,  -0.13768666,\n",
       "         -0.20684914,  -0.60148343,   1.79244754,   0.72782501,\n",
       "         -0.68731954,   0.26153252,   0.26899264,  -0.53059637,\n",
       "        112.96309068, -99.9511588 , -48.82875626]),\n",
       " array([ -1.77354709,   8.80052469,   7.29826839,  -3.33271325,\n",
       "         -2.08411345,   5.4256808 ,   7.59180764,  -0.13770798,\n",
       "         -0.20672221,  -0.60119874,   1.79240116,   0.7277127 ,\n",
       "         -0.68734845,   0.26153212,   0.26900689,  -0.53111398,\n",
       "        113.07265596, -99.96992559, -48.93040498]),\n",
       " array([ -1.77347462,   8.8003562 ,   7.29847242,  -3.3327251 ,\n",
       "         -2.08419709,   5.42571363,   7.59240209,  -0.13772415,\n",
       "         -0.20662603,  -0.60098301,   1.79236605,   0.7276276 ,\n",
       "         -0.68737037,   0.26153183,   0.26901771,  -0.5315065 ,\n",
       "        113.15572296, -99.98412652, -49.00747947]),\n",
       " array([ -1.77341973,   8.80022854,   7.29862666,  -3.33273404,\n",
       "         -2.08426031,   5.42573848,   7.59285224,  -0.1377364 ,\n",
       "         -0.20655316,  -0.6008196 ,   1.79233948,   0.72756313,\n",
       "         -0.68738697,   0.2615316 ,   0.26902591,  -0.53180399,\n",
       "        113.21866622, -99.99487162, -49.06588735]),\n",
       " array([  -1.77337816,    8.80013185,    7.29874329,   -3.33274078,\n",
       "          -2.08430811,    5.4257573 ,    7.59319304,   -0.13774567,\n",
       "          -0.20649799,   -0.60069587,    1.79231937,    0.72751432,\n",
       "          -0.68739955,    0.26153143,    0.26903212,   -0.53202934,\n",
       "         113.26634136, -100.00300137,  -49.11013034]),\n",
       " array([  -1.77334669,    8.80005865,    7.29883147,   -3.33274587,\n",
       "          -2.08434425,    5.42577154,    7.59345099,   -0.1377527 ,\n",
       "          -0.20645621,   -0.6006022 ,    1.79230415,    0.72747737,\n",
       "          -0.68740907,    0.26153131,    0.26903682,   -0.5322    ,\n",
       "         113.30244074, -100.00915209,  -49.1436327 ]),\n",
       " array([  -1.77332287,    8.80000323,    7.29889816,   -3.33274971,\n",
       "          -2.08437158,    5.42578232,    7.59364621,   -0.13775801,\n",
       "          -0.2064246 ,   -0.6005313 ,    1.79229263,    0.7274494 ,\n",
       "          -0.68741627,    0.26153121,    0.26904038,   -0.5323292 ,\n",
       "         113.32976859, -100.01380537,  -49.16899556]),\n",
       " array([  -1.77330485,    8.79996129,    7.2989486 ,   -3.33275262,\n",
       "          -2.08439225,    5.42579047,    7.59379394,   -0.13776204,\n",
       "          -0.20640067,   -0.60047764,    1.79228392,    0.72742823,\n",
       "          -0.68742173,    0.26153114,    0.26904307,   -0.532427  ,\n",
       "         113.35045256, -100.01732569,  -49.18819285])]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "katsayilar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(lambdalar, katsayilar)\n",
    "ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TAHMİN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 376.25245449,  803.38498121,  496.17669652,  112.69554648,\n",
       "        427.60020221, 1003.6309402 ,  153.45713944,  361.33880956,\n",
       "        483.29143665,  916.91439669])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289.3447069600656"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train hatası\n",
    "RMSE = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351.3931585606396"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CV RMSE\n",
    "np.sqrt(np.mean(-cross_val_score(ridge_model, x_train, y_train, cv=10, scoring=\"neg_mean_squared_error\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test hatası\n",
    "y_pred = ridge_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356.80829057302253"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MODEL TUNING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356.80829057302253"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([735, 710, 544, 520, 180, 121, 283, 198,  95, 860, 864, 719, 480,\n",
       "       621, 109, 950, 422, 266, 215,  45,  96, 296,  30, 215, 359, 103,\n",
       "       617,  73, 317, 408, 891, 290, 101, 691, 244, 457,  11, 131, 385,\n",
       "       237, 160, 819,  75, 202, 900, 548, 640, 172, 299, 134, 578, 211,\n",
       "       650, 536, 364, 608, 902, 829, 981, 535, 803, 314,  81, 799, 269,\n",
       "       171, 511, 546, 146,  26, 627,   6, 481, 820, 294, 107, 144, 246,\n",
       "       338, 776, 884, 376, 363, 807, 686, 569, 526,  47, 166, 113, 168,\n",
       "       369, 714, 726, 602, 835, 696, 486, 167, 847])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdalar1 = np.random.randint(0, 1000, 100)\n",
    "lambdalar2 = 10**np.linspace(10,-2,100)*.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([5.00000000e+09, 3.78231664e+09, 2.86118383e+09, 2.16438064e+09,\n",
       "       1.63727458e+09, 1.23853818e+09, 9.36908711e+08, 7.08737081e+08,\n",
       "       5.36133611e+08, 4.05565415e+08, 3.06795364e+08, 2.32079442e+08,\n",
       "       1.75559587e+08, 1.32804389e+08, 1.00461650e+08, 7.59955541e+07,\n",
       "       5.74878498e+07, 4.34874501e+07, 3.28966612e+07, 2.48851178e+07,\n",
       "       1.88246790e+07, 1.42401793e+0...\n",
       "       3.28966612e-01, 2.48851178e-01, 1.88246790e-01, 1.42401793e-01,\n",
       "       1.07721735e-01, 8.14875417e-02, 6.16423370e-02, 4.66301673e-02,\n",
       "       3.52740116e-02, 2.66834962e-02, 2.01850863e-02, 1.52692775e-02,\n",
       "       1.15506485e-02, 8.73764200e-03, 6.60970574e-03, 5.00000000e-03]),\n",
       "        cv=10, fit_intercept=True, gcv_mode=None, normalize=True,\n",
       "        scoring='neg_mean_squared_error', store_cv_values=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgecv=RidgeCV(alphas=lambdalar2, scoring=\"neg_mean_squared_error\", cv=10, normalize=True)\n",
    "ridgecv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7599555414764666"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv2 = RidgeCV(alphas=lambdalar1, scoring=\"neg_mean_squared_error\",cv=10,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([664, 194, 740, 899, 838, 146, 532, 923, 678, 931,  55, 144, 669,\n",
       "       746, 614,  49,  88, 758, 978, 162, 665, 570, 616, 432, 723,  57,\n",
       "       837, 572, 886, 233, 862, 502, 897, 665, 500, 544, 571, 743, 824,\n",
       "       114, 932, 261, 930, 504, 190, 267, 490, 247, 192, 161, 852, 700,\n",
       "       611, 178, 841, 457, 750, 905, 793, 212, 987, 945, 702, 546, 343,\n",
       "       690, 257, 837, 934, 615, 127, 712, 848, 811,  34, 859, 813, 759,\n",
       "       250, 549,  45,  63, 351, 703, 627,  28, 503,  24, 898, 303, 789,\n",
       "       482, 773, 746, 868, 854, 752, 113, 925, 256]),\n",
       "        cv=10, fit_intercept=True, gcv_mode=None, normalize=True,\n",
       "        scoring='neg_mean_squared_error', store_cv_values=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgecv2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgecv2.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final model\n",
    "ridge_tuned = Ridge(alpha= ridgecv.alpha_).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356.85830472715014"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ridge_tuned.predict(x_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final model\n",
    "ridge_tuned1 = Ridge(alpha= ridgecv2.alpha_).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356.53676786086464"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ridge_tuned1.predict(x_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ELASTICNET REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic Net first emerged as a result of critique on lasso, whose variable selection can be too dependent on data and thus unstable. The solution is to combine the penalties of ridge regression and lasso to get the best of both worlds. Elastic Net aims at minimizing the following loss function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where α is the mixing parameter between ridge (α = 0) and lasso (α = 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there are two parameters to tune: λ and α. The glmnet package allows to tune λ via cross-validation for a fixed α, but it does not support α-tuning, so we will turn to caret for this job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](14.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CODING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\PYTON\\\\Desktop\\\\machine_learning\\\\Handan_Olgar\\\\original2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dms =pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis=1).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([x_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>497</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2703</td>\n",
       "      <td>806</td>\n",
       "      <td>32</td>\n",
       "      <td>379</td>\n",
       "      <td>311</td>\n",
       "      <td>138</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>325</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>492</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>5511</td>\n",
       "      <td>1511</td>\n",
       "      <td>39</td>\n",
       "      <td>897</td>\n",
       "      <td>451</td>\n",
       "      <td>875</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>313</td>\n",
       "      <td>381</td>\n",
       "      <td>20</td>\n",
       "      <td>875.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>475</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1700</td>\n",
       "      <td>433</td>\n",
       "      <td>7</td>\n",
       "      <td>217</td>\n",
       "      <td>93</td>\n",
       "      <td>146</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>385.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>573</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>3198</td>\n",
       "      <td>857</td>\n",
       "      <td>97</td>\n",
       "      <td>470</td>\n",
       "      <td>420</td>\n",
       "      <td>332</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>1314</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>960.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>631</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>4908</td>\n",
       "      <td>1457</td>\n",
       "      <td>30</td>\n",
       "      <td>775</td>\n",
       "      <td>357</td>\n",
       "      <td>249</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  \\\n",
       "1      315    81      7    24   38     39     14    3449    835      69   \n",
       "2      479   130     18    66   72     76      3    1624    457      63   \n",
       "3      496   141     20    65   78     37     11    5628   1575     225   \n",
       "4      321    87     10    39   42     30      2     396    101      12   \n",
       "5      594   169      4    74   51     35     11    4408   1133      19   \n",
       "..     ...   ...    ...   ...  ...    ...    ...     ...    ...     ...   \n",
       "317    497   127      7    65   48     37      5    2703    806      32   \n",
       "318    492   136      5    76   50     94     12    5511   1511      39   \n",
       "319    475   126      3    61   43     52      6    1700    433       7   \n",
       "320    573   144      9    85   60     78      8    3198    857      97   \n",
       "321    631   170      9    77   44     31     11    4908   1457      30   \n",
       "\n",
       "     CRuns  CRBI  CWalks League Division  PutOuts  Assists  Errors  Salary  \\\n",
       "1      321   414     375      N        W      632       43      10   475.0   \n",
       "2      224   266     263      A        W      880       82      14   480.0   \n",
       "3      828   838     354      N        E      200       11       3   500.0   \n",
       "4       48    46      33      N        E      805       40       4    91.5   \n",
       "5      501   336     194      A        W      282      421      25   750.0   \n",
       "..     ...   ...     ...    ...      ...      ...      ...     ...     ...   \n",
       "317    379   311     138      N        E      325        9       3   700.0   \n",
       "318    897   451     875      A        E      313      381      20   875.0   \n",
       "319    217    93     146      A        W       37      113       7   385.0   \n",
       "320    470   420     332      A        E     1314      131      12   960.0   \n",
       "321    775   357     249      A        W      408        4       3  1000.0   \n",
       "\n",
       "    NewLeague  \n",
       "1           N  \n",
       "2           A  \n",
       "3           N  \n",
       "4           N  \n",
       "5           A  \n",
       "..        ...  \n",
       "317         N  \n",
       "318         A  \n",
       "319         A  \n",
       "320         A  \n",
       "321         A  \n",
       "\n",
       "[263 rows x 20 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8487984.799367314, tolerance: 3898.686956380658\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "enet_model = ElasticNet().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.86256172,   8.70489065,   5.10426375,  -2.89875799,\n",
       "        -1.28642985,   5.24343682,   6.04480276,  -0.14701495,\n",
       "        -0.21566628,  -0.7897201 ,   1.80813117,   0.80914508,\n",
       "        -0.61262382,   0.26816203,   0.27172387,  -0.36530729,\n",
       "        19.2186222 , -31.16586592,   8.98369938])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.465955602113581"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 325.74706292,  776.06632333,  522.86508419,  107.64091955,\n",
       "        449.03139566,  997.76095723,   99.78828622,  311.33763086,\n",
       "        418.50335021,  879.9502608 , 1628.05423879,  831.63172575,\n",
       "        909.34196881,  715.67274292,  601.33595953,  657.40417507,\n",
       "       1068.2110763 ,  149.6849625 ,  190.40513329,  385.31235163,\n",
       "        752.37991572, 1022.76166475,  486.94874949,  349.7945189 ,\n",
       "         69.28225147,  783.98489255,  551.11613877,  205.84644387,\n",
       "        367.25234577,  303.22135065,   98.44933333,  533.19866378,\n",
       "       1000.16419322,  245.20490159,  448.10920305,  401.93188524,\n",
       "        457.71559572,  713.00914559,  333.18157434,  235.45584771,\n",
       "        210.52615243,  309.20890759,  190.6560382 ,  183.01443111,\n",
       "        238.19688018, 1080.44877923,  380.19569305,  551.45922356,\n",
       "        278.3820838 ,  338.53829531,  427.9529666 ,  476.71228336,\n",
       "        297.09609267,  435.8113557 ,  592.18850471,  320.60291497,\n",
       "        510.97484699,  698.77992314,  218.04297483, 1535.95190547,\n",
       "        293.10294265,  189.6299643 ,  234.90776798,  292.46815931,\n",
       "        207.24518123,  818.58104675,  150.51114025,  436.90141101,\n",
       "        227.80627101,  269.85875334,  228.75251874,  780.27519788,\n",
       "        790.36841186,  741.23503574, 1471.96251995,  488.41242285,\n",
       "        541.340134  ,  475.37932197,  333.97175487,  980.7843625 ,\n",
       "        643.39081546,  506.9794147 ,  649.83293921,  657.68449241,\n",
       "        104.01854397,  770.91177319,  792.76875776, 1111.41642422,\n",
       "       1099.71214918,  687.51265812,  294.10741874,  234.27767447,\n",
       "       1152.45117423,  183.93307336,  416.51170979, 1250.71311433,\n",
       "       1069.48439424,  472.06592669,  774.67244657,  717.23343434,\n",
       "        403.94514963,  284.75403794,  635.563956  , 1367.1386377 ,\n",
       "        426.62941453, 1387.50330574,  788.84926559,  241.97390702,\n",
       "         81.08356292,  706.29629041,  711.58342115,  490.4396005 ,\n",
       "        297.57395148,  602.92224964,  508.11006727,  474.12896418,\n",
       "        882.09816344,  751.00437516,  357.20084916,  437.13439809,\n",
       "        583.87140404,  745.9400723 , 1095.58826183,  230.422316  ,\n",
       "         67.43611578,  462.88657696, 1333.51100827,  179.44710228,\n",
       "        175.02625103,  574.86154315,  864.61114064,  751.34019514,\n",
       "       1063.33937786,  792.97192467,  805.58654591,  271.79287773,\n",
       "        681.48678634,  301.90547349,  318.18177591,  854.62559948,\n",
       "         88.88633801,  323.13973702,  328.57213353,  610.07706981,\n",
       "        160.77168119,  304.03494572,  208.57272221,  495.22439088,\n",
       "        542.02278066, 1131.38585393,  304.83922126,  138.00288021,\n",
       "        225.79384761,  220.99925679,  807.46978324,  176.31037592,\n",
       "       1060.79953783,   82.56736518,  883.28621752,  590.85539065,\n",
       "        271.74633798,  392.51784598, 1325.87568879,  152.77512134,\n",
       "        563.94879139,  722.74191545,  383.97710112,  205.75411198,\n",
       "        687.09863653,  555.76395905,  757.14018923,  218.42681886,\n",
       "        589.69766034,  853.80452947,  236.54404615,  261.69506818,\n",
       "        314.24244215,  751.62770032,  573.53145529, 1008.25667824,\n",
       "        185.92925298,  442.71794918,  218.86121002,  569.79705306,\n",
       "        462.86048261,  818.8213985 ,  625.42364577,  568.07903425,\n",
       "        201.63756561,  360.92335494,  211.78706205,  849.65108444,\n",
       "       1220.03033522, 1286.49474847,  433.04566885,  705.66251327,\n",
       "        200.30497031])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 577.79111731,  617.33202224, 1031.39113156,  364.95861575,\n",
       "        489.51894393,  300.74185842,  604.522666  ,  465.34678732,\n",
       "        901.44473965,  703.20357123,  702.9157117 ,  931.50283407,\n",
       "        184.87939803,  385.14973787,  325.38944176,  546.99346574,\n",
       "        774.28001821,  101.83114992, 1250.86758812,  370.67651244,\n",
       "        442.05734523,  781.17288513,  578.63736538,  609.31927808,\n",
       "        608.31719597,  227.46556223,  921.85505228,  301.1202457 ,\n",
       "        386.31721051,  133.61143326,  162.28505608,   88.29793182,\n",
       "        359.9068418 ,  422.51268445,  265.8663769 ,  355.70450908,\n",
       "       1329.36312363,  125.05506935,   82.74580002,  269.17483075,\n",
       "        117.13319397,  274.13484779,  648.4957249 ,  409.47065999,\n",
       "        846.27919406,  712.04817644,  341.10596674,  368.24259678,\n",
       "        305.70477656,  680.05724792,  716.13640636,  295.93204262,\n",
       "        773.06445823,  249.28224916,  221.46794589,  541.2713245 ,\n",
       "        611.50212372,  770.80228024,  168.45143906, 1159.05660731,\n",
       "       1655.73440058,  487.79019015, 1013.23932071,  443.91500502,\n",
       "        613.83293616,  152.85401115])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = enet_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357.1676548181246"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41070222469326867"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **model tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(10,-2,100)*.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3249.9483051374555, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4337.003150258213, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5751.424798319116, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7379.353670164943, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 403437.83366297744, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 830826.1639666157, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 130519.54009712487, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16208.634067617357, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26112.429251603782, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3770.5528118126094, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 303635.4049203191, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003274.7480766037, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4450942.482335198, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5076765.911125852, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5391765.4884409765, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5573248.080912381, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5681629.329314823, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5747782.4766043695, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5789065.553007692, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5815540.98118378, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5833100.855748611, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5845191.968625668, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5853820.205627172, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5860154.834881244, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5864893.009214583, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5868472.143266927, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5867746.131141086, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5873611.935416417, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5875662.91914659, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5876891.76474321, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5877773.730829993, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5068.215613564476, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 204999.40599522926, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 788560.463127045, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2293668.962264329, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3430169.558240127, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4266665.682904968, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4870647.824411214, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5297167.789734992, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5584497.027111476, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5754281.625768617, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5809358.87149127, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5722512.074448034, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5393143.789192895, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4434425.350813108, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 484441.14108554274, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2783414.5334500363, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5975136.862095317, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6820441.680786386, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7120638.717471919, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7333370.775529609, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7414553.816965916, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7443957.252644329, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7439651.712343758, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7404015.090552562, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7326382.335976809, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7167831.008526282, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6772597.150061357, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4619307.030263741, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5534121.276819596, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6869433.40008194, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7182664.606087437, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7315966.544342676, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7386668.739494204, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11511.098290806636, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 81379.2452632226, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 241727.76615206525, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 680957.620382553, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1638971.1928743282, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2297235.39166746, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2818353.6068227347, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3097616.625563534, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3184180.183720056, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3031082.672878217, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2463821.21138369, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 917192.3066423032, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 132457.0060564205, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1852773.1293051923, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4556079.46335947, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5576668.58460539, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6060811.213315079, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6323270.5521305725, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6477932.480453692, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6574695.784596003, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6624598.960616562, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6682253.440164675, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6713509.8037538575, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6735111.156498842, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6750665.369163485, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6761964.209244537, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6770192.132120629, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6776191.462058888, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6780573.481857009, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6783782.767810878, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6786141.360953151, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6787881.556064353, tolerance: 3214.8159286012715\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20504.169900152832, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71606.78675394505, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 122229.86728449166, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182682.98624759167, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 249424.513485251, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1123238.6090622842, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2148501.1988901626, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2745746.290545224, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3153414.020708657, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3392561.3715442056, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3445739.3665164057, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3235674.159004857, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2517427.1308488688, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 520968.4330418352, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56213.6892941799, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3271147.061020486, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5516096.030909296, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6385036.3220796, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6810502.567490866, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7023285.9819713235, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7152847.1623571245, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7232464.533519229, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7283621.3050827915, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7317942.164048129, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7341835.157870563, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7358938.76033952, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7364032.720927623, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7381303.943804502, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7388673.04393717, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7393671.591979054, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7397333.992296298, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7400049.191085204, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7402068.964994214, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7403575.105745448, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33665.311698280275, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27693.861895602196, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77056.52701533772, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 128742.79614442587, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 234841.14299851842, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 655320.8009362593, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1585529.038567746, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2359230.378764292, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2943774.482143703, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3878962.383226811, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4062263.565757408, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4058048.0876655662, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3711498.0180912307, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2542575.8853194313, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 220218.33682131022, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1865508.5266558155, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5578616.631411916, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6542007.226423486, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7017443.5492488295, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7257492.536161805, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7388367.454979142, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7463707.915141214, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7494212.161893556, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7537511.396960707, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7556544.730561595, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7568392.799493961, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7576252.732468325, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7581520.439548936, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7585036.025481509, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7587359.901819267, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7588880.142543233, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7589866.422551073, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7590503.358334939, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7590914.62337491, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7591181.315437496, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51104.90983889252, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 86001.20450099371, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 124299.87200851552, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 163171.28424883448, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 199613.01662855223, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 226297.59154513106, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 236325.4833804518, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 222091.5074517429, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 175489.45560277626, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92900.06610616297, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5688.2456234022975, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2438817.7014393713, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4551640.49084264, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5666781.227074336, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6274516.979566201, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6618924.05073987, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6819925.021511015, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6939888.740026609, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7012853.650852241, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7058050.445064313, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7076979.858043507, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7105751.217422159, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7116703.743422874, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7127849.608458714, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7131404.05515645, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7134893.576431883, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7137346.992026175, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7139015.166536362, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7140147.3461527545, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7140919.228706851, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7141449.454145097, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7141817.185766478, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4891.730596676469, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21878.274436896667, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56824.895188070834, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 200353.91865239292, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 342303.45619017445, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 531378.5046477877, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1659301.3144448847, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2711701.220582407, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3504700.3154904265, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4070925.32321904, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4459448.611618344, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4704667.306904332, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4821661.20272927, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4799994.379926162, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4581093.935726732, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3967734.812347686, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2125357.828038832, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 155148.45919013582, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3641768.3555592867, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5531980.261255859, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6233312.055640772, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6577908.2114067525, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6773934.302731087, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6869192.62629479, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6977555.602308655, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7034830.7971826, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7073919.740693558, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7101814.536968857, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7121974.106219983, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7136638.085902766, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7147356.819704208, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7155226.8770733755, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7161030.439558935, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7165327.889283137, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7168522.249421605, tolerance: 3343.7655139011267\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16776.72525755316, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 313915.67215342075, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 438819.2484156266, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 903233.6304750927, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1444700.7960756216, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1710822.5213091932, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1578407.4690505676, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 787482.6686649807, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 288554.60017823987, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16065.330461405218, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3295353.0152510162, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5441477.637966018, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6368596.005842594, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6830870.435710062, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7082059.059514463, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7225920.736785891, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7311264.696813345, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7363290.947868375, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7395832.277142307, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7416780.639663291, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7430735.873268048, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7440400.532308296, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7447361.138836903, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7452547.105448373, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7453614.117372574, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7459988.382832064, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7462722.527142472, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7464625.655259623, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7466082.051930259, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7467208.53320868, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68689.9180047363, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 202989.7044456452, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 332828.8635005001, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 880949.4115489572, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2098415.5445614345, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3098659.2634697016, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3817727.75508577, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4305199.30266594, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4592808.14376165, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4677254.178274194, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4487185.564037997, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3736616.4255743017, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1028870.7481734585, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56857.203364662826, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5137785.2420635335, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6520863.619265748, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7062855.428526301, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7301030.6140951775, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7462897.773431597, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7549964.3920744965, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7598803.374409557, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7628772.887954639, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7647769.367365067, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7660037.809656173, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7668031.832874721, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7673234.956885434, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7676587.922993587, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7678713.422236722, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7680033.83989011, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7680836.232985765, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7681312.766943215, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7681589.053057936, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7681745.058109849, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41948.8375218492, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 896764.1448438112, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2063539.3986952864, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3320899.452744157, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4463993.916813817, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5375668.589864794, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6228631.125927539, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6520080.941226847, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6894283.32013106, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7061780.991063433, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7159825.69705268, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7220550.207941299, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7258207.00759606, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7281265.425050617, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7294955.722895432, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7302573.40485478, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7306264.598721837, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7307479.599656129, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7307219.086557096, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7306167.637436513, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7304775.828092856, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7303321.303257094, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7301959.051341592, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7300762.3280833, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\PYTON\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7299753.917521355, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n"
     ]
    }
   ],
   "source": [
    "enet_cv_model = ElasticNetCV(alphas=alphas,cv=10).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5748.784976988678"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_cv_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-31.46312122564109"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_cv_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.61111381,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.11212622,  0.        ,\n",
       "        0.25252702,  0.18656722,  0.00444355,  0.30988823,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_cv_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_tuned = ElasticNet(enet_cv_model.alpha_).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = enet_tuned.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393.9753065850553"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2- NON-LINEAR REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **K-Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the image above that most of the time, similar data points are close to each other. The KNN algorithm hinges on this assumption being true enough for the algorithm to be useful. KNN captures the idea of similarity (sometimes called distance, proximity, or closeness) with some mathematics we might have learned in our childhood— calculating the distance between points on a graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other ways of calculating distance, and one way might be preferable depending on the problem we are solving. However, the straight-line distance (also called the Euclidean distance) is a popular and familiar choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The KNN Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Load the data\\n2. Initialize K to your chosen number of neighbors\\n3. For each example in the data\\n3.1 Calculate the distance between the query example and the current example from the data.\\n3.2 Add the distance and the index of the example to an ordered collection\\n4. Sort the ordered collection of distances and indices from smallest to largest (in ascending order) by the distances\\n5. Pick the first K entries from the sorted collection\\n6. Get the labels of the selected K entries\\n7. If regression, return the mean of the K labels\\n8. If classification, return the mode of the K labels'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"1. Load the data\n",
    "2. Initialize K to your chosen number of neighbors\n",
    "3. For each example in the data\n",
    "3.1 Calculate the distance between the query example and the current example from the data.\n",
    "3.2 Add the distance and the index of the example to an ordered collection\n",
    "4. Sort the ordered collection of distances and indices from smallest to largest (in ascending order) by the distances\n",
    "5. Pick the first K entries from the sorted collection\n",
    "6. Get the labels of the selected K entries\n",
    "7. If regression, return the mean of the K labels\n",
    "8. If classification, return the mode of the K labels\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Choosing the right value for K**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the K that’s right for your data, we run the KNN algorithm several times with different values of K and choose the K that reduces the number of errors we encounter while maintaining the algorithm’s ability to accurately make predictions when it’s given data it hasn’t seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some things to keep in mind:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1--As we decrease the value of K to 1, our predictions become less stable. Just think for a minute, imagine K=1 and we have a query point surrounded by several reds and one green (I’m thinking about the top left corner of the colored plot above), but the green is the single nearest neighbor. Reasonably, we would think the query point is most likely red, but because K=1, KNN incorrectly predicts that the query point is green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2--Inversely, as we increase the value of K, our predictions become more stable due to majority voting / averaging, and thus, more likely to make more accurate predictions (up to a certain point). Eventually, we begin to witness an increasing number of errors. It is at this point we know we have pushed the value of K too far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3--In cases where we are taking a majority vote (e.g. picking the mode in a classification problem) among labels, we usually make K an odd number to have a tiebreaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Advantages**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1--The algorithm is simple and easy to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2--There’s no need to build a model, tune several parameters, or make additional assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3--The algorithm is versatile. It can be used for classification, regression, and search (as we will see in the next section)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Disadvantages**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1--The algorithm gets significantly slower as the number of examples and/or predictors/independent variables increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CODING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np       \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\PYTON\\\\Desktop\\\\machine_learning\\\\Handan_Olgar\\\\original3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "dms =pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis=1).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([x_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>328.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>514.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4739.0</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>593.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2765.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>233.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>341.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2964.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat   Hits  HmRun  Runs   RBI  Walks  Years  CAtBat   CHits  CHmRun  \\\n",
       "183  328.0   91.0   12.0  51.0  43.0   33.0    2.0   342.0    94.0    12.0   \n",
       "229  514.0  144.0    0.0  67.0  54.0   79.0    9.0  4739.0  1169.0    13.0   \n",
       "286  593.0  152.0   23.0  69.0  75.0   53.0    6.0  2765.0   686.0   133.0   \n",
       "102  233.0   49.0    2.0  41.0  23.0   18.0    8.0  1350.0   336.0     7.0   \n",
       "153  341.0   95.0    6.0  48.0  42.0   20.0   10.0  2964.0   808.0    81.0   \n",
       "\n",
       "     CRuns   CRBI  CWalks  PutOuts  Assists  Errors  League_N  Division_W  \\\n",
       "183   51.0   44.0    33.0    145.0     59.0     8.0         1           0   \n",
       "229  583.0  374.0   528.0    229.0    453.0    15.0         1           0   \n",
       "286  369.0  384.0   321.0    315.0     10.0     6.0         0           1   \n",
       "102  166.0  122.0   106.0    102.0    132.0    10.0         0           0   \n",
       "153  379.0  428.0   221.0    158.0      4.0     5.0         1           1   \n",
       "\n",
       "     NewLeague_N  \n",
       "183            1  \n",
       "229            1  \n",
       "286            0  \n",
       "102            0  \n",
       "153            1  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsRegressor().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 510.3334,  808.3334,  772.5   ,  125.5   , 1005.    ,  325.5   ,\n",
       "        216.5   ,  101.5   ,  982.    ,  886.6666,  590.    ,  901.6666,\n",
       "        831.6666,  157.5   ,  393.    , 1005.    ,  735.5   ,   97.    ,\n",
       "        884.4   ,  302.    ,  450.    ,  817.6666,  832.6666,  392.3334,\n",
       "        528.    ,   81.6   ,  735.    ,  470.    ,  722.5   ,  101.    ,\n",
       "         90.5   ,   74.6   ,  748.3334,  217.    ,  280.5334, 1044.5   ,\n",
       "        955.    ,  232.    ,   78.6   ,  529.    ,   77.6   ,  106.5   ,\n",
       "        516.6666,  593.6666, 1005.    ,  649.1666,  715.    ,  101.5   ,\n",
       "        134.5   ,  810.    ,  743.    ,  521.3334,  664.3334,  195.    ,\n",
       "        102.4   ,  728.5   ,  488.    ,  962.5   ,  230.8334, 1040.    ,\n",
       "        885.    ,  542.    ,  720.4   ,  571.    ,  735.    ,   81.6   ])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn_model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426.6570764525201"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **KNN MODEL TUNING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EL YORDAMIYLA K DEĞERİNİ BELİRLEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1 için rmse değeri:  455.03925390751965\n",
      "k: 2 için rmse değeri:  415.99629571490965\n",
      "k: 3 için rmse değeri:  420.6765370082348\n",
      "k: 4 için rmse değeri:  428.8564674588792\n",
      "k: 5 için rmse değeri:  426.6570764525201\n",
      "k: 6 için rmse değeri:  423.5071669008732\n",
      "k: 7 için rmse değeri:  414.9361222421057\n",
      "k: 8 için rmse değeri:  413.7094731463598\n",
      "k: 9 için rmse değeri:  417.84419990871265\n",
      "k: 10 için rmse değeri:  421.6252180741266\n"
     ]
    }
   ],
   "source": [
    "RMSE = list()\n",
    "for k in range(10):\n",
    "    k += 1\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k).fit(x_train, y_train)\n",
    "    y_pred = knn_model.predict(x_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    RMSE.append(rmse)\n",
    "    print(\"k:\",k,\"için rmse değeri: \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\"n_neighbors\": np.arange(1,30,1)}\n",
    "knn = KNeighborsRegressor()\n",
    "knn_cv_model = GridSearchCV(knn, knn_params, cv=10).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 8}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final modeli\n",
    "knn_tuned = KNeighborsRegressor(n_neighbors=knn_cv_model.best_params_[\"n_neighbors\"]).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413.7094731463598"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn_tuned.predict(x_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SUPPORT VECTOR REGRESSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter Support Vector Regression. SVR gives us the flexibility to define how much error is acceptable in our model and will find an appropriate line (or hyperplane in higher dimensions) to fit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to OLS, the objective function of SVR is to minimize the coefficients — more specifically, the l2-norm of the coefficient vector — not the squared error. The error term is instead handled in the constraints, where we set the absolute error less than or equal to a specified margin, called the maximum error, ϵ (epsilon). We can tune epsilon to gain the desired accuracy of our model. Our new objective function and constraints are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Minimize:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Constraints:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Illustrative Example:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Giving Ourselves some Slack (and another Hyperparameter)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of slack variables is simple: for any value that falls outside of ϵ, we can denote its deviation from the margin as ξ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that these deviations have the potential to exist, but we would still like to minimize them as much as possible. Thus, we can add these deviations to the objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Minimize:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](19.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Constraints:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Illustrative Example:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](21.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CODING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\PYTON\\\\Desktop\\\\machine_learning\\\\Handan_Olgar\\\\original3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "dms =pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis=1).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([x_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>328.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>514.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4739.0</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>593.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2765.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>233.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>341.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2964.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat   Hits  HmRun  Runs   RBI  Walks  Years  CAtBat   CHits  CHmRun  \\\n",
       "183  328.0   91.0   12.0  51.0  43.0   33.0    2.0   342.0    94.0    12.0   \n",
       "229  514.0  144.0    0.0  67.0  54.0   79.0    9.0  4739.0  1169.0    13.0   \n",
       "286  593.0  152.0   23.0  69.0  75.0   53.0    6.0  2765.0   686.0   133.0   \n",
       "102  233.0   49.0    2.0  41.0  23.0   18.0    8.0  1350.0   336.0     7.0   \n",
       "153  341.0   95.0    6.0  48.0  42.0   20.0   10.0  2964.0   808.0    81.0   \n",
       "\n",
       "     CRuns   CRBI  CWalks  PutOuts  Assists  Errors  League_N  Division_W  \\\n",
       "183   51.0   44.0    33.0    145.0     59.0     8.0         1           0   \n",
       "229  583.0  374.0   528.0    229.0    453.0    15.0         1           0   \n",
       "286  369.0  384.0   321.0    315.0     10.0     6.0         0           1   \n",
       "102  166.0  122.0   106.0    102.0    132.0    10.0         0           0   \n",
       "153  379.0  428.0   221.0    158.0      4.0     5.0         1           1   \n",
       "\n",
       "     NewLeague_N  \n",
       "183            1  \n",
       "229            1  \n",
       "286            0  \n",
       "102            0  \n",
       "153            1  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(\"linear\").fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([679.14754685, 633.72883069, 925.68640849, 270.28463621,\n",
       "       530.26659184])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model.predict(x_test)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-80.15196151])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.21839037,   6.09602969,  -3.67574533,   0.14217075,\n",
       "          0.51435919,   1.28388986,  12.55922537,  -0.08693755,\n",
       "          0.46597184,   2.98259944,   0.52944523,  -0.79820799,\n",
       "         -0.16015534,   0.30872794,   0.28842348,  -1.79560067,\n",
       "          6.41868985, -10.74313783,   1.33374317]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370.04084185624924"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_params = {\"C\": [.1,.5,1.3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_cv_model = GridSearchCV(svr_model, svr_params, cv=5).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   59.8s finished\n"
     ]
    }
   ],
   "source": [
    "svr_cv_model = GridSearchCV(svr_model, svr_params, cv=5, verbose=2, n_jobs = -1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_tuned = SVR(\"linear\", C=.5).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svr_tuned.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367.9874739022889"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ARTIFICIAL NEURAL NETWORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Neurons**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biological Neurons (also called nerve cells) or simply neurons are the fundamental units of the brain and nervous system, the cells responsible for receiving sensory input from the external world via dendrites, process it and gives the output through Axons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell body (Soma):** The body of the neuron cell contains the nucleus and carries out biochemical transformation necessary to the life of neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dendrites:** Each neuron has fine, hair-like tubular structures (extensions) around it. They branch out into a tree around the cell body. They accept incoming signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Axon:** It is a long, thin, tubular structure that works like a transmission line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Synapse:** Neurons are connected to one another in a complex spatial arrangement. When axon reaches its final destination it branches again called terminal arborization. At the end of the axon are highly complex and specialized structures called synapses. The connection between two neurons takes place at these synapses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dendrites receive input through the synapses of other neurons. The soma processes these incoming signals over time and converts that processed value into an output, which is sent out to other neurons through the axon and the synapse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following diagram represents the general model of ANN which is inspired by a biological neuron. It is also called Perceptron.\n",
    "A single layer neural network is called a Perceptron. It gives a single output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](23.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, for one single observation, x0, x1, x2, x3...x(n) represents various inputs(independent variables) to the network. Each of these inputs is multiplied by a connection weight or synapse. The weights are represented as w0, w1, w2, w3….w(n) . **Weight shows the strength of a particular node.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b** is a bias value. A bias value allows you to shift the activation function up or down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the simplest case, these products are summed, fed to a transfer function (activation function) to generate a result, and this result is sent as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, x1.w1 + x2.w2 + x3.w3 ...... xn.wn = ∑ xi.wi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now activation function is applied 𝜙(∑ xi.wi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Activation function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Activation function is important for an ANN to learn and make sense of something really complicated. Their main purpose is to convert an input signal of a node in an ANN to an output signal. This output signal is used as input to the next layer in the stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activation function decides whether a neuron should be activated or not by calculating the weighted sum and further adding bias to it. The motive is to introduce non-linearity into the output of a neuron.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not apply activation function then the output signal would be simply linear function(one-degree polynomial). Now, a linear function is easy to solve but they are limited in their complexity, have less power. Without activation function, our model cannot learn and model complicated data such as images, videos, audio, speech, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-Linear functions are those which have a degree more than one and they have a curvature. Now we need a neural network to learn and represent almost anything and any arbitrary complex function that maps an input to output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network is considered **“Universal Function Approximators”**. It means they can learn and compute any function at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Types of Activation Functions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Threshold Activation Function — (Binary step function)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation function A = “activated” if Y > threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "else not or A=1 if y>threshold 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with this function is for creating a binary classifier ( 1 or 0), but if you want multiple such neurons to be connected to bring in more classes, Class1, Class2, Class3, etc. In this case, all neurons will give 1, so we cannot decide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Sigmoid Activation Function — (Logistic function)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Sigmoid function is a mathematical function having a characteristic “S”-shaped curve or sigmoid curve which ranges between 0 and 1, therefore it is used for models where we need to predict the probability as an output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sigmoid function is differentiable, means we can find the slope of the curve at any 2 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drawback of the Sigmoid activation function is that it can cause the neural network to get stuck at training time if strong negative input is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Hyperbolic Tangent Function — (tanh)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is similar to Sigmoid but better in performance. It is nonlinear in nature, so great we can stack layers. The function ranges between (-1,1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](26.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantage of this function is that strong negative inputs will be mapped to negative output and only zero-valued inputs are mapped to near-zero outputs.,So less likely to get stuck during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Rectified Linear Units — (ReLu)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLu is the most used activation function in CNN and ANN which ranges from zero to infinity. [0,∞)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](27.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gives an output ‘x’ if x is positive and 0 otherwise. It looks like having the same problem of linear function as it is linear in the positive axis. Relu is non-linear in nature and a combination of ReLu is also non-linear. In fact, it is a good approximator and any function can be approximated with a combination of Relu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLu is 6 times improved over hyperbolic tangent function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should only be applied to hidden layers of a neural network. So, for the output layer use softmax function for classification problem and for regression problem use a Linear function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here one problem is some gradients are fragile during training and can die. It causes a weight update which will make it never activate on any data point again. Basically ReLu could result in dead neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix the problem of dying neurons, Leaky ReLu was introduced. So, Leaky ReLu introduces a small slope to keep the updates alive. Leaky ReLu ranges from -∞ to +∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](28.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leak helps to increase the range of the ReLu function. Usually, the value of a = 0.01 or so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a is not 0.01, then it is called Randomized ReLu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How does the Neural network work?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take the example of the price of a property and to start with we have different factors assembled in a single row of data: Area, Bedrooms, Distance to city and Age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input values go through the weighted synapses straight over to the output layer. All four will be analyzed, an activation function will be applied, and the results will be produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simple enough but there is a way to amplify the power of the Neural Network and increase its accuracy by the addition of a hidden layer that sits between the input and output layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](30.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in the above figure, all 4 variables are connected to neurons via a synapse. However, not all of the synapses are weighted. they will either have a 0 value or non-0 value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here, the non-0 value → indicates the importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 value → They will be discarded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the example of Area and Distance to City are non-zero for the first neuron, which means they are weighted and matter to the first neuron. The other two variables, Bedrooms and Age aren’t weighted and so are not considered by the first neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may wonder why that first neuron is only considering two of the four variables. In this case, it is common on the property market that larger homes become cheaper the further they are from the city. That’s a basic fact. So what this neuron may be doing is looking specifically for properties that are large but are not so far from the city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this is where the power of neural networks comes from. There are many of these neurons, each doing similar calculations with different combinations of these variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this criterion has been met, the neuron applies the activation function and do its calculations. The next neuron down may have weighted synapses of Distance to the city and, Bedrooms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way the neurons work and interact in a very flexible way allowing it to look for specific things and therefore make a comprehensive search for whatever it is trained for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CODING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\PYTON\\\\Desktop\\\\machine_learning\\\\Handan_Olgar\\\\original3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "dms =pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis=1).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([x_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL TAHMİN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLPRegressor().fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20.64074451,  38.37144234,  67.36129784,  14.41690475,\n",
       "        20.63787555,  11.48958031,  13.0881775 ,  12.04060948,\n",
       "        72.80772699,  35.41498445,  22.3549564 ,  69.66966515,\n",
       "        21.43326664,  27.6549566 ,   5.67783508,  43.54550548,\n",
       "        50.02992031,  11.7202496 ,  55.4866868 ,   9.21351961,\n",
       "         7.75681142,  39.72405648,  12.10666232,  11.90146929,\n",
       "        42.21112599,  14.03899126,  64.72012528,   6.54956219,\n",
       "        22.05847549,  12.7914762 ,  12.98819737,  21.99234588,\n",
       "         7.07212725,  21.30181187,  10.28220956,  33.25241574,\n",
       "       113.67218792,   5.52767237,  18.22500721,  11.0077573 ,\n",
       "        13.33693598,   8.33288205,   6.16420805,   4.85296311,\n",
       "        71.62332999,  32.46279982,  11.75553864,   8.32204421,\n",
       "         9.41053587,  28.71218489,  33.58861661,   8.71762559,\n",
       "        30.13331259,   7.60591044,  12.25527129,  22.51687128,\n",
       "         8.55908085,  41.52680865,  14.16150529, 109.79779836,\n",
       "       116.92224918,   9.94930119,  35.50982391,   4.35988507,\n",
       "        29.89183682,  14.87129222])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =mlp_model.predict(x_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661.4856004311359"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL TUNING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_params ={\"alpha\": [.1, .01, .02, .001, .0001],\n",
    "            \"hidden_layer_sizes\": [(10, 20), (5, 5), (100, 100)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "mlp_cv_model = GridSearchCV(mlp_model, mlp_params, cv=10, verbose=2, n_jobs = -1).fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.02, 'hidden_layer_sizes': (100, 100)}"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_tuned = MLPRegressor(alpha = 0.02, hidden_layer_sizes = (100, 100)).fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 336.61447226,  699.00304166,  967.50512413,  422.38245846,\n",
       "        273.23668762,  242.67693943,  429.80277731,  374.86320114,\n",
       "       1118.93556395,  379.98832325,  540.56895282,  907.54392171,\n",
       "        354.03834873,  711.58555076,  122.37092522,  535.68943783,\n",
       "        932.24242962,  239.84629735, 1010.78078348,  190.81345108,\n",
       "        213.41194442,  788.44148751,  311.20670002,  379.42668318,\n",
       "        849.4021195 ,  294.53158349,  876.64207448,  137.02067856,\n",
       "        327.38237839,  272.11840259,  288.3653895 ,  466.3354053 ,\n",
       "        162.05218792,  415.24110423,  218.69650719,  417.51733259,\n",
       "       1595.90506679,  105.60168621,  399.71911941,  265.2750807 ,\n",
       "        268.33546603,  159.10197452,  183.06080082,  169.82866747,\n",
       "       1019.69690016,  540.67753505,  240.60633697,  144.30379379,\n",
       "        216.04220303,  617.39427256,  513.5645755 ,  229.61066246,\n",
       "        596.70510947,  222.76521281,  273.37393188,  550.22609217,\n",
       "        261.74202047,  550.23070949,  345.5237651 , 1544.59688789,\n",
       "       1710.32132722,  275.51226106,  760.07373693,  126.3565642 ,\n",
       "        441.57480404,  317.0052347 ])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =mlp_tuned.predict(x_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358.74918560288205"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Classification and Regression Tree (CART)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree is a supervised machine learning model used to predict a target by learning decision rules from features. As the name suggests, we can think of this model as breaking down our data by making a decision based on asking a series of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the following example in which we use a decision tree to decide upon an activity on a particular day:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](31.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the features in our training set, the decision tree model learns a series of questions to infer the class labels of the samples. As we can see, decision trees are attractive models if we care about interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the preceding figure illustrates the concept of a decision tree based on categorical targets (classification), the same concept applies if our targets are real numbers (regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The Fundamentals of Decision Trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree is constructed by recursive partitioning — starting from the root node (known as the first parent), each node can be split into left and right child nodes. These nodes can then be further split and they themselves become parent nodes of their resulting children nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, looking at the image above, the root node is Work to do? and splits into the child nodes Stay in and Outlook based on whether or not there is work to do. The Outlook node further splits into three child nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how do we know what the optimal splitting point is at each node?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the root, the data is split on the feature that results in the largest **Information Gain (IG)** (explained in more detail below). In an iterative process, we then repeat this splitting procedure at each **child node** until the leaves are pure — i.e. samples at each node all belong to the same class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, this can result in a very deep tree with many nodes, which can easily lead to overfitting. Thus, we typically want to prune the tree by setting a limit for the maximal depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CODING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\PYTON\\\\Desktop\\\\machine_learning\\\\Handan_Olgar\\\\original3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "dms =pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis=1).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([x_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(x_train[\"Hits\"])\n",
    "x_test = pd.DataFrame(x_test[\"Hits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hits\n",
       "183   91.0\n",
       "229  144.0\n",
       "286  152.0\n",
       "102   49.0\n",
       "153   95.0\n",
       "..     ...\n",
       "24   168.0\n",
       "236   52.0\n",
       "93   138.0\n",
       "137  103.0\n",
       "133   99.0\n",
       "\n",
       "[197 rows x 1 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hits\n",
       "148  136.0\n",
       "154  147.0\n",
       "318  136.0\n",
       "279   96.0\n",
       "88    41.0\n",
       "..     ...\n",
       "122  139.0\n",
       "282  210.0\n",
       "111   76.0\n",
       "232   83.0\n",
       "51    53.0\n",
       "\n",
       "[66 rows x 1 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MODEL VE TAHMİN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_model = DecisionTreeRegressor().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_grid = np.arange(min(np.array(x_train)),max(np.array(x_train)), .01)\n",
    "x_grid = x_grid.reshape((len(x_grid),1))\n",
    "\n",
    "plt.scatter(x_train, y_train, color=\"red\")\n",
    "\n",
    "plt.plot(x_grid, cart_model.predict(x_grid), color =\"blue\")\n",
    "\n",
    "plt.title(\"CART REGRESSION AĞACI\")\n",
    "plt.xlabel(\"ATIŞ SAYISI (Hits)\")\n",
    "plt.ylabel(\"MAAŞ (Salary)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TAHMİN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEK DEĞİŞKENLİ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cart_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.49579052913884"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TÜM DEĞİŞKENLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\PYTON\\\\Desktop\\\\machine_learning\\\\Handan_Olgar\\\\original3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "dms =pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis=1).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([x_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_model = DecisionTreeRegressor().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cart_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444.6850242558822"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MODEL TURING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_model = DecisionTreeRegressor().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cart_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515.1228557306558"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_params = {\"max_depth\": [2,3,4,5,10,20],\n",
    "              \"min_samples_split\": [2,5,10,20,30,50,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 42 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 420 out of 420 | elapsed:    6.4s finished\n"
     ]
    }
   ],
   "source": [
    "cart_cv_model = GridSearchCV(cart_model, cart_params, cv= 10, verbose=2, n_jobs = -1).fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'min_samples_split': 50}"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_tuned = DecisionTreeRegressor(max_depth = 4, min_samples_split = 50).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cart_tuned.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361.0876906511434"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Random Forest Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ensemble Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Ensemble method is a technique that combines the predictions from multiple machine learning algorithms together to make more accurate predictions than any individual model. A model comprised of many models is called an Ensemble model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](32.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Types of Ensemble Learning:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1--Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2--Bootstrap Aggregation (Bagging)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Boosting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting refers to a group of algorithms that utilize weighted averages to make weak learners into stronger learners. Boosting is all about “teamwork”. Each model that runs, dictates what features the next model will focus on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In boosting as the name suggests, one is learning from other which in turn boosts the learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Bootstrap Aggregation (Bagging)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap refers to random sampling with replacement. Bootstrap allows us to better understand the bias and the variance with the dataset. Bootstrap involves random sampling of small subset of data from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a general procedure that can be used to reduce the variance for those algorithm that have high variance, typically decision trees. Bagging makes each model run independently and then aggregates the outputs at the end without preference to any model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](33.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is a Supervised Learning algorithm which uses ensemble learning method for classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is a bagging technique and not a boosting technique. The trees in random forests are run in parallel. There is no interaction between these trees while building the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random forest is a meta-estimator (i.e. it combines the result of multiple predictions) which aggregates many decision trees, with some helpful modifications:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1--The number of features that can be split on at each node is limited to some percentage of the total (which is known as the hyperparameter). This ensures that the ensemble model does not rely too heavily on any individual feature, and makes fair use of all potentially predictive features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2--Each tree draws a random sample from the original data set when generating its splits, adding a further element of randomness that prevents overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above modifications help prevent the trees from being too highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature and Advantages of Random Forest :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1--It is one of the most accurate learning algorithms available. For many data sets, it produces a highly accurate classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2--It runs efficiently on large databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3--It can handle thousands of input variables without variable deletion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4--It gives estimates of what variables that are important in the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5--It generates an internal unbiased estimate of the generalization error as the forest building progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6--It has an effective method for estimating missing data and maintains accuracy when a large proportion of the data are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Disadvantages of Random Forest :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1--Random forests have been observed to overfit for some datasets with noisy classification/regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2--For data including categorical variables with different number of levels, random forests are biased in favor of those attributes with more levels. Therefore, the variable importance scores from random forest are not reliable for this type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CODING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\PYTON\\\\Desktop\\\\machine_learning\\\\Handan_Olgar\\\\original3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "dms =pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis=1).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([x_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>328.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>514.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4739.0</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>593.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2765.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>233.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>341.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2964.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat   Hits  HmRun  Runs   RBI  Walks  Years  CAtBat   CHits  CHmRun  \\\n",
       "183  328.0   91.0   12.0  51.0  43.0   33.0    2.0   342.0    94.0    12.0   \n",
       "229  514.0  144.0    0.0  67.0  54.0   79.0    9.0  4739.0  1169.0    13.0   \n",
       "286  593.0  152.0   23.0  69.0  75.0   53.0    6.0  2765.0   686.0   133.0   \n",
       "102  233.0   49.0    2.0  41.0  23.0   18.0    8.0  1350.0   336.0     7.0   \n",
       "153  341.0   95.0    6.0  48.0  42.0   20.0   10.0  2964.0   808.0    81.0   \n",
       "\n",
       "     CRuns   CRBI  CWalks  PutOuts  Assists  Errors  League_N  Division_W  \\\n",
       "183   51.0   44.0    33.0    145.0     59.0     8.0         1           0   \n",
       "229  583.0  374.0   528.0    229.0    453.0    15.0         1           0   \n",
       "286  369.0  384.0   321.0    315.0     10.0     6.0         0           1   \n",
       "102  166.0  122.0   106.0    102.0    132.0    10.0         0           0   \n",
       "153  379.0  428.0   221.0    158.0      4.0     5.0         1           1   \n",
       "\n",
       "     NewLeague_N  \n",
       "183            1  \n",
       "229            1  \n",
       "286            0  \n",
       "102            0  \n",
       "153            1  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(random_state =42).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344.73852779396566"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params= {\"max_depth\": [5,10],\n",
    "           \"max_features\": [2,5,10],\n",
    "           \"n_estimators\": [500,2000],\n",
    "           \"min_samples_split\": [10,80,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   59.4s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 10.6min finished\n"
     ]
    }
   ],
   "source": [
    "rf_cv_model = GridSearchCV(rf_model, rf_params, cv=10, verbose=2, n_jobs = -1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 2,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=10, max_features=2, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=500, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_tuned = RandomForestRegressor(random_state=42, max_depth=10, max_features=2, min_samples_split=10, n_estimators=500)\n",
    "rf_tuned.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_tuned.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342.7001918875625"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEĞİŞKEN ÖNEM DÜZEYİ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05932584, 0.0548487 , 0.03297582, 0.04122085, 0.05437988,\n",
       "       0.05495865, 0.06058294, 0.09311945, 0.09069375, 0.08445456,\n",
       "       0.0990687 , 0.0961137 , 0.09932382, 0.04143416, 0.01613185,\n",
       "       0.01295282, 0.00221048, 0.00406355, 0.00214048])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_tuned.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Importance = pd.DataFrame({\"Importance\": rf_tuned.feature_importances_*100},\n",
    "                         index = x_train.columns)\n",
    "\n",
    "Importance.sort_values(by=\"Importance\",\n",
    "                      axis=0,\n",
    "                      ascending=True).plot(kind=\"barh\",\n",
    "                                          color=\"r\")\n",
    "plt.xlabel(\"Variable Importance\")\n",
    "plt.gca().legend_ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Çalışmalarım sırasında Gradient Boosting Machines, XGBoost, LightGBM ve CatBoost Algoritmalarını da inceledim. Fakat tuning kısmı n_jobs=-1 olmasına rağmen (yani bilgisayarda CPU yu maximum seviyede kullanmama reğmen) yarım saat ve/ya civarında sürdüğü için tekrar çalıştırmak istemedim. Bu sebeple o algoritmalara yer vermedim.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LOGISTIC REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A solution for classification is logistic regression. Instead of fitting a straight line or hyperplane, the logistic regression model uses the logistic function to squeeze the output of a linear equation between 0 and 1. The logistic function is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](34.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](35.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The step from linear regression to logistic regression is kind of straightforward. In the linear regression model, we have modelled the relationship between outcome and features with a linear equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](36.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification, we prefer probabilities between 0 and 1, so we wrap the right side of the equation into the logistic function. This forces the output to assume only values between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](37.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us revisit the tumor size example again. But instead of the linear regression model, we use the logistic regression model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](38.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification works better with logistic regression and we can use 0.5 as a threshold in both cases. The inclusion of additional points does not really affect the estimated curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Interpretation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpretation of the weights in logistic regression differs from the interpretation of the weights in linear regression, since the outcome in logistic regression is a probability between 0 and 1. The weights do not influence the probability linearly any longer. The weighted sum is transformed by the logistic function to a probability. Therefore we need to reformulate the equation for the interpretation so that only the linear term is on the right side of the formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](39.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the term in the log() function “odds” (probability of event divided by probability of no event) and wrapped in the logarithm it is called log odds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This formula shows that the logistic regression model is a linear model for the log odds. Great! That does not sound helpful! With a little shuffling of the terms, you can figure out how the prediction changes when one of the features  \n",
    "x_j is changed by 1 unit. To do this, we can first apply the exp() function to both sides of the equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](40.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we compare what happens when we increase one of the feature values by 1. But instead of looking at the difference, we look at the ratio of the two predictions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](41.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the following rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](42.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we remove many terms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](43.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we have something as simple as exp() of a feature weight. A change in a feature by one unit changes the odds ratio (multiplicative) by a factor of exp(β_j). We could also interpret it this way: A change in x_j by one unit increases the log odds ratio by the value of the corresponding weight. Most people interpret the odds ratio because thinking about the log() of something is known to be hard on the brain. Interpreting the odds ratio already requires some getting used to. For example, if you have odds of 2, it means that the probability for y=1 is twice as high as y=0. If you have a weight (= log odds ratio) of 0.7, then increasing the respective feature by one unit multiplies the odds by exp(0.7) (approximately 2) and the odds change to 4. But usually you do not deal with the odds and interpret the weights only as the odds ratios. Because for actually calculating the odds you would need to set a value for each feature, which only makes sense if you want to look at one specific instance of your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the interpretations for the logistic regression model with different feature types:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1--Numerical feature: If you increase the value of feature x_j by one unit, the estimated odds change by a factor of exp(β_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2--Binary categorical feature: One of the two values of the feature is the reference category (in some languages, the one encoded in 0). Changing the feature x_j from the reference category to the other category changes the estimated odds by a factor of exp(β_j)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3--Categorical feature with more than two categories: One solution to deal with multiple categories is one-hot-encoding, meaning that each category has its own column. You only need L-1 columns for a categorical feature with L categories, otherwise it is over-parameterized. The L-th category is then the reference category. You can use any other encoding that can be used in linear regression. The interpretation for each category then is equivalent to the interpretation of binary features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4--Intercept β_0: When all numerical features are zero and the categorical features are at the reference category, the estimated odds are exp(β_0). The interpretation of the intercept weight is usually not relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Advantages and Disadvantages**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the pros and cons of the linear regression model also apply to the logistic regression model. Logistic regression has been widely used by many different people, but it struggles with its restrictive expressiveness (e.g. interactions must be added manually) and other models may have better predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another disadvantage of the logistic regression model is that the interpretation is more difficult because the interpretation of the weights is multiplicative and not additive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression can suffer from complete separation. If there is a feature that would perfectly separate the two classes, the logistic regression model can no longer be trained. This is because the weight for that feature would not converge, because the optimal weight would be infinite. This is really a bit unfortunate, because such a feature is really useful. But you do not need machine learning if you have a simple rule that separates both classes. The problem of complete separation can be solved by introducing penalization of the weights or defining a prior probability distribution of weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the good side, the logistic regression model is not only a classification model, but also gives you probabilities. This is a big advantage over models that can only provide the final classification. Knowing that an instance has a 99% probability for a class compared to 51% makes a big difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression can also be extended from binary classification to multi-class classification. Then it is called Multinomial Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CODING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np       \n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVR, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"C:\\\\Users\\\\PYTON\\\\Desktop\\\\machine_learning\\\\Classification_Models\\\\diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>768.0</td>\n",
       "      <td>3.845052</td>\n",
       "      <td>3.369578</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>768.0</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>117.0000</td>\n",
       "      <td>140.25000</td>\n",
       "      <td>199.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>768.0</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>72.0000</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>122.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>768.0</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>768.0</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>127.25000</td>\n",
       "      <td>846.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>768.0</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.30000</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>36.60000</td>\n",
       "      <td>67.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>768.0</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.24375</td>\n",
       "      <td>0.3725</td>\n",
       "      <td>0.62625</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>768.0</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>21.000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <td>768.0</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.476951</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count        mean         std     min       25%  \\\n",
       "Pregnancies               768.0    3.845052    3.369578   0.000   1.00000   \n",
       "Glucose                   768.0  120.894531   31.972618   0.000  99.00000   \n",
       "BloodPressure             768.0   69.105469   19.355807   0.000  62.00000   \n",
       "SkinThickness             768.0   20.536458   15.952218   0.000   0.00000   \n",
       "Insulin                   768.0   79.799479  115.244002   0.000   0.00000   \n",
       "BMI                       768.0   31.992578    7.884160   0.000  27.30000   \n",
       "DiabetesPedigreeFunction  768.0    0.471876    0.331329   0.078   0.24375   \n",
       "Age                       768.0   33.240885   11.760232  21.000  24.00000   \n",
       "Outcome                   768.0    0.348958    0.476951   0.000   0.00000   \n",
       "\n",
       "                               50%        75%     max  \n",
       "Pregnancies                 3.0000    6.00000   17.00  \n",
       "Glucose                   117.0000  140.25000  199.00  \n",
       "BloodPressure              72.0000   80.00000  122.00  \n",
       "SkinThickness              23.0000   32.00000   99.00  \n",
       "Insulin                    30.5000  127.25000  846.00  \n",
       "BMI                        32.0000   36.60000   67.10  \n",
       "DiabetesPedigreeFunction    0.3725    0.62625    2.42  \n",
       "Age                        29.0000   41.00000   81.00  \n",
       "Outcome                     0.0000    1.00000    1.00  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Outcome\"]\n",
    "x = df.drop([\"Outcome\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  \n",
       "2                     0.672   32  \n",
       "3                     0.167   21  \n",
       "4                     2.288   33  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(solver=\"liblinear\").fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.88892806])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.17021185e-01,  2.83796791e-02, -1.68945985e-02,\n",
       "         7.55781327e-04, -6.41918440e-04,  5.97429918e-02,\n",
       "         6.76379270e-01,  7.23757055e-03]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.predict(x)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[448,  52],\n",
       "       [121, 147]], dtype=int64)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7747395833333334"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       500\n",
      "           1       0.74      0.55      0.63       268\n",
      "\n",
      "    accuracy                           0.77       768\n",
      "   macro avg       0.76      0.72      0.73       768\n",
      "weighted avg       0.77      0.77      0.77       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35051741, 0.64948259],\n",
       "       [0.91696618, 0.08303382],\n",
       "       [0.22485241, 0.77514759],\n",
       "       ...,\n",
       "       [0.76722317, 0.23277683],\n",
       "       [0.69746534, 0.30253466],\n",
       "       [0.89052148, 0.10947852]])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit_roc_auc = roc_auc_score(y, log_model.predict(x))\n",
    "fpr, tpr, thresholds = roc_curve(y, log_model.predict_proba(x)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"AUC (area=%.3f)\"%logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1], \"r--\")\n",
    "plt.xlim([.0, 1.0])\n",
    "plt.ylim([.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"Log_ROC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(solver=\"liblinear\").fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7748188405797102"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(log_model, x_test, y_test, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **K-Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DAHA ÖNCE BU KONUYLA İLGİLİ TEORİK BİLGİ VERDİĞİM İÇİN TEKRAR YAZMIYORUM.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Outcome\"]\n",
    "x = df.drop([\"Outcome\"], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model=KNeighborsClassifier().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=knn_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6883116883116883\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76       151\n",
      "           1       0.55      0.56      0.56        80\n",
      "\n",
      "    accuracy                           0.69       231\n",
      "   macro avg       0.66      0.66      0.66       231\n",
      "weighted avg       0.69      0.69      0.69       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\"n_neighbors\": np.arange(1, 50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 49 candidates, totalling 490 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 490 out of 490 | elapsed:    8.8s finished\n"
     ]
    }
   ],
   "source": [
    "knn_cv_model = GridSearchCV(knn, knn_params, cv=10, n_jobs=-1, verbose=2).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 11}"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_tuned = KNeighborsClassifier(n_neighbors = 11).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_tuned.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7316017316017316"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7316017316017316"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_tuned.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80       151\n",
      "           1       0.62      0.57      0.60        80\n",
      "\n",
      "    accuracy                           0.73       231\n",
      "   macro avg       0.70      0.69      0.70       231\n",
      "weighted avg       0.73      0.73      0.73       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit_roc_auc = roc_auc_score(y, knn_cv_model.predict(x))\n",
    "fpr, tpr, thresholds = roc_curve(y, knn_cv_model.predict_proba(x)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"AUC (area=%.3f)\"%logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1], \"r--\")\n",
    "plt.xlim([.0, 1.0])\n",
    "plt.ylim([.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"Log_ROC1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Support Vector Machines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DAHA ÖNCE BU KONUYLA İLGİLİ TEORİK BİLGİ VERDİĞİM İÇİN TEKRAR YAZMIYORUM.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Outcome\"]\n",
    "x = df.drop([\"Outcome\"], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='linear').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7445887445887446"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81       151\n",
      "           1       0.63      0.62      0.63        80\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.72      0.72      0.72       231\n",
      "weighted avg       0.74      0.74      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {\"C\": np.arange(1,10),\n",
    "             \"kernel\": [\"linear\", \"rbf\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  7.9min finished\n"
     ]
    }
   ],
   "source": [
    "svm_cv_model=GridSearchCV(svm_model, svm_params, cv=5, n_jobs=-1, verbose=2).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7839044652128765"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cv_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tuned = SVC(C=2, kernel=\"linear\").fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_tuned.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7445887445887446"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81       151\n",
      "           1       0.63      0.62      0.63        80\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.72      0.72      0.72       231\n",
      "weighted avg       0.74      0.74      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DAHA ÖNCE BU KONUYLA İLGİLİ TEORİK BİLGİ VERDİĞİM İÇİN TEKRAR YAZMIYORUM.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Outcome\"]\n",
    "x = df.drop([\"Outcome\"], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(x_test)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc_model = MLPClassifier().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= mlpc_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7402597402597403"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        MLPClassifier\n",
       "\u001b[1;31mString form:\u001b[0m\n",
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "           beta_ <...>               tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "           warm_start=False)\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\users\\pyton\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "Multi-layer Perceptron classifier.\n",
       "\n",
       "This model optimizes the log-loss function using LBFGS or stochastic\n",
       "gradient descent.\n",
       "\n",
       ".. versionadded:: 0.18\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "hidden_layer_sizes : tuple, length = n_layers - 2, default=(100,)\n",
       "    The ith element represents the number of neurons in the ith\n",
       "    hidden layer.\n",
       "\n",
       "activation : {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
       "    Activation function for the hidden layer.\n",
       "\n",
       "    - 'identity', no-op activation, useful to implement linear bottleneck,\n",
       "      returns f(x) = x\n",
       "\n",
       "    - 'logistic', the logistic sigmoid function,\n",
       "      returns f(x) = 1 / (1 + exp(-x)).\n",
       "\n",
       "    - 'tanh', the hyperbolic tan function,\n",
       "      returns f(x) = tanh(x).\n",
       "\n",
       "    - 'relu', the rectified linear unit function,\n",
       "      returns f(x) = max(0, x)\n",
       "\n",
       "solver : {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
       "    The solver for weight optimization.\n",
       "\n",
       "    - 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
       "\n",
       "    - 'sgd' refers to stochastic gradient descent.\n",
       "\n",
       "    - 'adam' refers to a stochastic gradient-based optimizer proposed\n",
       "      by Kingma, Diederik, and Jimmy Ba\n",
       "\n",
       "    Note: The default solver 'adam' works pretty well on relatively\n",
       "    large datasets (with thousands of training samples or more) in terms of\n",
       "    both training time and validation score.\n",
       "    For small datasets, however, 'lbfgs' can converge faster and perform\n",
       "    better.\n",
       "\n",
       "alpha : float, default=0.0001\n",
       "    L2 penalty (regularization term) parameter.\n",
       "\n",
       "batch_size : int, default='auto'\n",
       "    Size of minibatches for stochastic optimizers.\n",
       "    If the solver is 'lbfgs', the classifier will not use minibatch.\n",
       "    When set to \"auto\", `batch_size=min(200, n_samples)`\n",
       "\n",
       "learning_rate : {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
       "    Learning rate schedule for weight updates.\n",
       "\n",
       "    - 'constant' is a constant learning rate given by\n",
       "      'learning_rate_init'.\n",
       "\n",
       "    - 'invscaling' gradually decreases the learning rate at each\n",
       "      time step 't' using an inverse scaling exponent of 'power_t'.\n",
       "      effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
       "\n",
       "    - 'adaptive' keeps the learning rate constant to\n",
       "      'learning_rate_init' as long as training loss keeps decreasing.\n",
       "      Each time two consecutive epochs fail to decrease training loss by at\n",
       "      least tol, or fail to increase validation score by at least tol if\n",
       "      'early_stopping' is on, the current learning rate is divided by 5.\n",
       "\n",
       "    Only used when ``solver='sgd'``.\n",
       "\n",
       "learning_rate_init : double, default=0.001\n",
       "    The initial learning rate used. It controls the step-size\n",
       "    in updating the weights. Only used when solver='sgd' or 'adam'.\n",
       "\n",
       "power_t : double, default=0.5\n",
       "    The exponent for inverse scaling learning rate.\n",
       "    It is used in updating effective learning rate when the learning_rate\n",
       "    is set to 'invscaling'. Only used when solver='sgd'.\n",
       "\n",
       "max_iter : int, default=200\n",
       "    Maximum number of iterations. The solver iterates until convergence\n",
       "    (determined by 'tol') or this number of iterations. For stochastic\n",
       "    solvers ('sgd', 'adam'), note that this determines the number of epochs\n",
       "    (how many times each data point will be used), not the number of\n",
       "    gradient steps.\n",
       "\n",
       "shuffle : bool, default=True\n",
       "    Whether to shuffle samples in each iteration. Only used when\n",
       "    solver='sgd' or 'adam'.\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    If int, random_state is the seed used by the random number generator;\n",
       "    If RandomState instance, random_state is the random number generator;\n",
       "    If None, the random number generator is the RandomState instance used\n",
       "    by `np.random`.\n",
       "\n",
       "tol : float, default=1e-4\n",
       "    Tolerance for the optimization. When the loss or score is not improving\n",
       "    by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,\n",
       "    unless ``learning_rate`` is set to 'adaptive', convergence is\n",
       "    considered to be reached and training stops.\n",
       "\n",
       "verbose : bool, default=False\n",
       "    Whether to print progress messages to stdout.\n",
       "\n",
       "warm_start : bool, default=False\n",
       "    When set to True, reuse the solution of the previous\n",
       "    call to fit as initialization, otherwise, just erase the\n",
       "    previous solution. See :term:`the Glossary <warm_start>`.\n",
       "\n",
       "momentum : float, default=0.9\n",
       "    Momentum for gradient descent update. Should be between 0 and 1. Only\n",
       "    used when solver='sgd'.\n",
       "\n",
       "nesterovs_momentum : boolean, default=True\n",
       "    Whether to use Nesterov's momentum. Only used when solver='sgd' and\n",
       "    momentum > 0.\n",
       "\n",
       "early_stopping : bool, default=False\n",
       "    Whether to use early stopping to terminate training when validation\n",
       "    score is not improving. If set to true, it will automatically set\n",
       "    aside 10% of training data as validation and terminate training when\n",
       "    validation score is not improving by at least tol for\n",
       "    ``n_iter_no_change`` consecutive epochs. The split is stratified,\n",
       "    except in a multilabel setting.\n",
       "    Only effective when solver='sgd' or 'adam'\n",
       "\n",
       "validation_fraction : float, default=0.1\n",
       "    The proportion of training data to set aside as validation set for\n",
       "    early stopping. Must be between 0 and 1.\n",
       "    Only used if early_stopping is True\n",
       "\n",
       "beta_1 : float, default=0.9\n",
       "    Exponential decay rate for estimates of first moment vector in adam,\n",
       "    should be in [0, 1). Only used when solver='adam'\n",
       "\n",
       "beta_2 : float, default=0.999\n",
       "    Exponential decay rate for estimates of second moment vector in adam,\n",
       "    should be in [0, 1). Only used when solver='adam'\n",
       "\n",
       "epsilon : float, default=1e-8\n",
       "    Value for numerical stability in adam. Only used when solver='adam'\n",
       "\n",
       "n_iter_no_change : int, default=10\n",
       "    Maximum number of epochs to not meet ``tol`` improvement.\n",
       "    Only effective when solver='sgd' or 'adam'\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "max_fun : int, default=15000\n",
       "    Only used when solver='lbfgs'. Maximum number of loss function calls.\n",
       "    The solver iterates until convergence (determined by 'tol'), number\n",
       "    of iterations reaches max_iter, or this number of loss function calls.\n",
       "    Note that number of loss function calls will be greater than or equal\n",
       "    to the number of iterations for the `MLPClassifier`.\n",
       "\n",
       "    .. versionadded:: 0.22\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "classes_ : ndarray or list of ndarray of shape (n_classes,)\n",
       "    Class labels for each output.\n",
       "\n",
       "loss_ : float\n",
       "    The current loss computed with the loss function.\n",
       "\n",
       "coefs_ : list, length n_layers - 1\n",
       "    The ith element in the list represents the weight matrix corresponding\n",
       "    to layer i.\n",
       "\n",
       "intercepts_ : list, length n_layers - 1\n",
       "    The ith element in the list represents the bias vector corresponding to\n",
       "    layer i + 1.\n",
       "\n",
       "n_iter_ : int,\n",
       "    The number of iterations the solver has ran.\n",
       "\n",
       "n_layers_ : int\n",
       "    Number of layers.\n",
       "\n",
       "n_outputs_ : int\n",
       "    Number of outputs.\n",
       "\n",
       "out_activation_ : string\n",
       "    Name of the output activation function.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "MLPClassifier trains iteratively since at each time step\n",
       "the partial derivatives of the loss function with respect to the model\n",
       "parameters are computed to update the parameters.\n",
       "\n",
       "It can also have a regularization term added to the loss function\n",
       "that shrinks model parameters to prevent overfitting.\n",
       "\n",
       "This implementation works with data represented as dense numpy arrays or\n",
       "sparse scipy arrays of floating point values.\n",
       "\n",
       "References\n",
       "----------\n",
       "Hinton, Geoffrey E.\n",
       "    \"Connectionist learning procedures.\" Artificial intelligence 40.1\n",
       "    (1989): 185-234.\n",
       "\n",
       "Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of\n",
       "    training deep feedforward neural networks.\" International Conference\n",
       "    on Artificial Intelligence and Statistics. 2010.\n",
       "\n",
       "He, Kaiming, et al. \"Delving deep into rectifiers: Surpassing human-level\n",
       "    performance on imagenet classification.\" arXiv preprint\n",
       "    arXiv:1502.01852 (2015).\n",
       "\n",
       "Kingma, Diederik, and Jimmy Ba. \"Adam: A method for stochastic\n",
       "    optimization.\" arXiv preprint arXiv:1412.6980 (2014).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?mlpc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc_params = {\"alpha\": [.1, .01, .03, .005, .0001, 1, 5],\n",
    "              \"hidden_layer_sizes\": [(10, 10), (100, 100, 100), (100, 100), (3, 5)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc = MLPClassifier(solver=\"lbfgs\", activation=\"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:  4.2min finished\n"
     ]
    }
   ],
   "source": [
    "mlpc_cv_model = GridSearchCV(mlpc, mlpc_params, cv=10, n_jobs=-1, verbose=2).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1, 'hidden_layer_sizes': (3, 5)}"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc_tuned = MLPClassifier(solver= \"lbfgs\", activation=\"logistic\", alpha=1, hidden_layer_sizes = (3, 5)).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlpc_tuned.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7532467532467533"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CARD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DAHA ÖNCE BU KONUYLA İLGİLİ TEORİK BİLGİ VERDİĞİM İÇİN TEKRAR YAZMIYORUM.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Outcome\"]\n",
    "x = df.drop([\"Outcome\"], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_model = DecisionTreeRegressor().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = card_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77       151\n",
      "           1       0.57      0.68      0.62        80\n",
      "\n",
      "    accuracy                           0.71       231\n",
      "   macro avg       0.69      0.71      0.70       231\n",
      "weighted avg       0.73      0.71      0.72       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "card = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_params = {\"max_depth\": [1,3,5,8,10],\n",
    "            \"min_samples_split\": [2,3,5,10,20,50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 291 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "card_cv_model = GridSearchCV(card, card_params, cv=10, verbose=2, n_jobs=-1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_samples_split': 20}"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_tuned = DecisionTreeClassifier(max_depth = 5, min_samples_split = 20).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = card_tuned.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7532467532467533"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       151\n",
      "           1       0.67      0.57      0.62        80\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.73      0.71      0.72       231\n",
      "weighted avg       0.75      0.75      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RANDOM FOREST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DAHA ÖNCE BU KONUYLA İLGİLİ TEORİK BİLGİ VERDİĞİM İÇİN TEKRAR YAZMIYORUM.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = RandomForestClassifier().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7489177489177489"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81       151\n",
      "           1       0.64      0.62      0.63        80\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.72      0.72      0.72       231\n",
      "weighted avg       0.75      0.75      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_params = {\"n_estimators\": [100,200,500,1000],\n",
    "                \"max_features\": [3,5,7,8],\n",
    "                \"min_samples_split\": [2,5,10,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 640 out of 640 | elapsed: 14.2min finished\n"
     ]
    }
   ],
   "source": [
    "forest_cv_model = GridSearchCV(forest_model, forest_params, cv=10, verbose=2, n_jobs=-1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 7, 'min_samples_split': 5, 'n_estimators': 200}"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_tuned = RandomForestClassifier(max_features = 7, min_samples_split = 5, n_estimators = 200).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest_tuned.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7445887445887446"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80       151\n",
      "           1       0.62      0.68      0.65        80\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.72      0.73      0.72       231\n",
      "weighted avg       0.75      0.74      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# değişken önem düzeyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_imp = pd.Series(forest_tuned.feature_importances_, index=x_train.columns).sort_values(ascending=False)\n",
    "\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "plt.xlabel(\"Değişken Önem Skorları\")\n",
    "plt.ylabel(\"Değişkenler\")\n",
    "plt.title(\"Değişken Önem Düzeyleri\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
